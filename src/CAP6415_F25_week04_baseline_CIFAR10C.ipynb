{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "6R832YeZBV3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import datetime\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def log_event(message: str) -> None:\n",
        "    \"\"\"Prints a timestamped log message.\"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] {message}\")\n",
        "\n",
        "\n",
        "def run_command(command: str) -> Tuple[int, str]:\n",
        "    \"\"\"Runs a shell command, returning (exit_code, output).\"\"\"\n",
        "    process = subprocess.Popen(\n",
        "        command,\n",
        "        shell=True,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "    output, _ = process.communicate()\n",
        "    return process.returncode, output\n",
        "\n",
        "\n",
        "def ensure_kaggle_config() -> bool:\n",
        "    \"\"\"Ensures kaggle.json exists and configures the Kaggle directory.\"\"\"\n",
        "    if not os.path.isfile(\"kaggle.json\"):\n",
        "        log_event(\"ERROR: kaggle.json not found. Please upload it.\")\n",
        "        return False\n",
        "\n",
        "    run_command(\"mkdir -p ~/.kaggle\")\n",
        "    run_command(\"cp kaggle.json ~/.kaggle/\")\n",
        "    run_command(\"chmod 600 ~/.kaggle/kaggle.json\")\n",
        "\n",
        "    log_event(\"Kaggle API credentials configured successfully.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def install_kaggle_api() -> None:\n",
        "    \"\"\"Ensures Kaggle API is installed.\"\"\"\n",
        "    log_event(\"Installing Kaggle API if missing...\")\n",
        "    run_command(\"pip install -q kaggle\")\n",
        "    log_event(\"Kaggle API installation attempted.\")\n",
        "\n",
        "\n",
        "def download_dataset(dataset_path: str) -> bool:\n",
        "    \"\"\"Attempts to download a Kaggle dataset.\"\"\"\n",
        "    log_event(f\"Starting dataset download: {dataset_path}\")\n",
        "    command = f\"kaggle datasets download -d {dataset_path}\"\n",
        "    code, output = run_command(command)\n",
        "\n",
        "    if code != 0:\n",
        "        log_event(\"ERROR: Kaggle download failed.\")\n",
        "        log_event(f\"Command Output:\\n{output}\")\n",
        "        return False\n",
        "\n",
        "    log_event(\"Dataset downloaded successfully.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def unzip_dataset(dataset_path: str) -> bool:\n",
        "    \"\"\"Attempts to unzip the downloaded dataset zip file.\"\"\"\n",
        "    zip_filename = f\"{dataset_path.split('/')[-1]}.zip\"\n",
        "\n",
        "    if not os.path.exists(zip_filename):\n",
        "        log_event(f\"ERROR: Expected zip file '{zip_filename}' not found.\")\n",
        "        return False\n",
        "\n",
        "    log_event(f\"Unzipping '{zip_filename}'...\")\n",
        "    code, output = run_command(f\"unzip -q {zip_filename}\")\n",
        "\n",
        "    if code != 0:\n",
        "        log_event(\"ERROR: Unzip failed.\")\n",
        "        log_event(f\"Command Output:\\n{output}\")\n",
        "        return False\n",
        "\n",
        "    log_event(\"Unzip completed successfully.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def download_kaggle_dataset(dataset_path: str) -> None:\n",
        "    \"\"\"Orchestrates full dataset download and extraction.\"\"\"\n",
        "    install_kaggle_api()\n",
        "\n",
        "    if not ensure_kaggle_config():\n",
        "        return\n",
        "\n",
        "    if not download_dataset(dataset_path):\n",
        "        log_event(\"Download process terminated due to errors.\")\n",
        "        return\n",
        "\n",
        "    if not unzip_dataset(dataset_path):\n",
        "        log_event(\"Unzip process terminated due to errors.\")\n",
        "        return\n",
        "\n",
        "    log_event(\"Dataset download and extraction completed successfully.\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "download_kaggle_dataset(\"harshadakhatu/cifar-10-c\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlisuoma5gVz",
        "outputId": "0e1544c7-10c9-4c05-8450-fe455faff38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-11-17 03:49:13] Installing Kaggle API if missing...\n",
            "[2025-11-17 03:49:18] Kaggle API installation attempted.\n",
            "[2025-11-17 03:49:18] Kaggle API credentials configured successfully.\n",
            "[2025-11-17 03:49:18] Starting dataset download: harshadakhatu/cifar-10-c\n",
            "[2025-11-17 03:51:54] Dataset downloaded successfully.\n",
            "[2025-11-17 03:51:54] Unzipping 'cifar-10-c.zip'...\n",
            "[2025-11-17 03:52:36] Unzip completed successfully.\n",
            "[2025-11-17 03:52:36] Dataset download and extraction completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory path\n",
        "directory_path = \"/content/CIFAR-10-C\"\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
        "    # List all files and directories within the specified path\n",
        "    files_and_dirs = os.listdir(directory_path)\n",
        "    print(f\"Contents of '{directory_path}':\")\n",
        "    for item in files_and_dirs:\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"The directory '{directory_path}' does not exist or is not a directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6VTQ-ig8d6x",
        "outputId": "b16e5176-39f1-4b23-e245-d25eb81c1d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of '/content/CIFAR-10-C':\n",
            "speckle_noise.npy\n",
            "gaussian_blur.npy\n",
            "fog.npy\n",
            "impulse_noise.npy\n",
            "jpeg_compression.npy\n",
            "motion_blur.npy\n",
            "snow.npy\n",
            "zoom_blur.npy\n",
            "saturate.npy\n",
            "spatter.npy\n",
            "labels.npy\n",
            "defocus_blur.npy\n",
            "shot_noise.npy\n",
            "gaussian_noise.npy\n",
            "brightness.npy\n",
            "glass_blur.npy\n",
            "elastic_transform.npy\n",
            "frost.npy\n",
            "pixelate.npy\n",
            "contrast.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `inspect_cifar10c.py`:  inspect /content/CIFAR-10-C .npy files\n"
      ],
      "metadata": {
        "id": "HWNWNWho_RAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect /content/CIFAR-10-C .npy files\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "ROOT = Path(\"/content/CIFAR-10-C\")   # change only if your path differs\n",
        "OUT = Path(\"results\")\n",
        "SAMPLES = OUT / \"samples\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "SAMPLES.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_image_array(arr: np.ndarray):\n",
        "    \"\"\"Heuristic check whether array looks like images (H/W/C shape and small H/W dimensions).\"\"\"\n",
        "    if arr.ndim == 4:\n",
        "        n, h, w, c = arr.shape\n",
        "        if c in (1,3) and (h <= 1024 and w <= 1024):\n",
        "            return True\n",
        "    if arr.ndim == 4 and arr.shape[1] in (1,3) and arr.shape[2] <= 1024:\n",
        "        # maybe N, C, H, W\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def to_uint8_image(arr: np.ndarray):\n",
        "    \"\"\"Convert array slice to uint8 HxW(xC) for saving. Accepts floats in [0,1] or ints [0,255].\"\"\"\n",
        "    if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
        "        img = np.clip(arr, 0.0, 1.0)\n",
        "        img = (img * 255.0).round().astype(np.uint8)\n",
        "    else:\n",
        "        img = arr.astype(np.uint8)\n",
        "    # if CHW -> HWC\n",
        "    if img.ndim == 3 and img.shape[0] in (1,3):\n",
        "        img = np.transpose(img, (1,2,0))\n",
        "    # if grayscale single channel -> HxW\n",
        "    if img.ndim == 3 and img.shape[2] == 1:\n",
        "        img = img[:,:,0]\n",
        "    return img\n",
        "\n",
        "report = {}\n",
        "files = sorted([p for p in ROOT.iterdir() if p.suffix == \".npy\"])\n",
        "if not files:\n",
        "    raise SystemExit(f\"No .npy files found in {ROOT}. Check path and rerun.\")\n",
        "\n",
        "print(f\"Found {len(files)} .npy files in {ROOT}\\n\")\n",
        "for p in files:\n",
        "    name = p.name\n",
        "    print(f\"Loading {name} ...\", end=\" \", flush=True)\n",
        "    arr = np.load(p)\n",
        "    print(\"done.\")\n",
        "    info = {\n",
        "        \"path\": str(p),\n",
        "        \"shape\": list(arr.shape),\n",
        "        \"dtype\": str(arr.dtype),\n",
        "        \"nbytes\": int(arr.nbytes) if hasattr(arr, \"nbytes\") else None,\n",
        "    }\n",
        "\n",
        "    # basic statistics if numeric\n",
        "    try:\n",
        "        info[\"min\"] = float(np.min(arr)) if arr.size>0 else None\n",
        "        info[\"max\"] = float(np.max(arr)) if arr.size>0 else None\n",
        "        info[\"mean\"] = float(np.mean(arr)) if arr.size>0 else None\n",
        "        info[\"std\"] = float(np.std(arr)) if arr.size>0 else None\n",
        "    except Exception as e:\n",
        "        info[\"stats_error\"] = str(e)\n",
        "\n",
        "    # Labels detection: likely 1D vector with length 10000\n",
        "    if arr.ndim == 1:\n",
        "        unique, counts = np.unique(arr, return_counts=True)\n",
        "        info[\"is_label_array\"] = True\n",
        "        info[\"unique_count\"] = int(len(unique))\n",
        "        info[\"length\"] = int(arr.shape[0])\n",
        "        info[\"unique_sample\"] = unique[:10].tolist()\n",
        "        info[\"counts_sample\"] = counts[:10].tolist()\n",
        "        # Save sample of labels to JSON-friendly list (first 200)\n",
        "        info[\"first_labels_sample\"] = arr[:200].tolist()\n",
        "    else:\n",
        "        info[\"is_label_array\"] = False\n",
        "\n",
        "    # Image file heuristics and per-severity analysis\n",
        "    if is_image_array(arr):\n",
        "        info[\"looks_like_images\"] = True\n",
        "        # Normalize shape to (N, H, W, C)\n",
        "        if arr.ndim == 4:\n",
        "            if arr.shape[1] in (1,3) and arr.shape[2] <= 1024:\n",
        "                # shape (N, C, H, W) -> convert to (N, H, W, C)\n",
        "                if arr.shape[1] in (1,3) and arr.shape[3] <= 4:\n",
        "                    # unexpected ordering, but handle common CHW or HWC\n",
        "                    pass\n",
        "            # Try to detect ordering\n",
        "            n = arr.shape[0]\n",
        "            if arr.shape[-1] in (1,3) and arr.shape[1] not in (1,3):\n",
        "                # likely (N,H,W,C)\n",
        "                n, h, w, c = arr.shape\n",
        "                arr_hwc = arr\n",
        "            elif arr.shape[1] in (1,3):\n",
        "                # likely (N,C,H,W) -> convert\n",
        "                n, c, h, w = arr.shape\n",
        "                arr_hwc = np.transpose(arr, (0,2,3,1))\n",
        "            else:\n",
        "                # fallback: treat as (N,H,W,C)\n",
        "                n, h, w, c = arr.shape\n",
        "                arr_hwc = arr\n",
        "        else:\n",
        "            info[\"image_format_note\"] = \"unexpected ndim for images\"\n",
        "            arr_hwc = arr\n",
        "\n",
        "        info[\"num_images_total\"] = int(arr_hwc.shape[0])\n",
        "\n",
        "        # detect severity grouping: divisible by 10000 (common CIFAR-10-C)\n",
        "        if arr_hwc.shape[0] % 10000 == 0:\n",
        "            groups = arr_hwc.shape[0] // 10000\n",
        "            info[\"num_severities_in_file\"] = int(groups)\n",
        "            info[\"per_severity_counts\"] = [10000] * groups\n",
        "            # compute simple per-severity stats (mean pixel value per channel)\n",
        "            per_sev = []\n",
        "            for s in range(groups):\n",
        "                start = s * 10000\n",
        "                end = (s + 1) * 10000\n",
        "                subset = arr_hwc[start:end].astype(np.float32) / (255.0 if arr_hwc.dtype != np.float32 and arr_hwc.dtype != np.float64 else 1.0)\n",
        "                # per-channel mean (HWC -> axis=(0,1,2), channel last)\n",
        "                mean_channels = list(np.mean(subset, axis=(0,1,2)).tolist())\n",
        "                std_channels = list(np.std(subset, axis=(0,1,2)).tolist())\n",
        "                per_sev.append({\"mean_channels\": mean_channels, \"std_channels\": std_channels})\n",
        "                # save one representative image per severity (first image)\n",
        "                try:\n",
        "                    img = to_uint8_image(subset[0])\n",
        "                    fname = SAMPLES / f\"{p.stem}_s{s+1}.png\"\n",
        "                    Image.fromarray(img).save(fname)\n",
        "                    per_sev[-1][\"saved_sample\"] = str(fname)\n",
        "                except Exception as e:\n",
        "                    per_sev[-1][\"saved_sample_error\"] = str(e)\n",
        "            info[\"per_severity_stats\"] = per_sev\n",
        "        else:\n",
        "            # not divisible by 10000: report number and attempt to treat as single-severity set\n",
        "            info[\"num_severities_in_file\"] = None\n",
        "            info[\"per_severity_counts\"] = [int(arr_hwc.shape[0])]\n",
        "            try:\n",
        "                subset = arr_hwc.astype(np.float32) / (255.0 if arr_hwc.dtype != np.float32 and arr_hwc.dtype != np.float64 else 1.0)\n",
        "                mean_channels = list(np.mean(subset, axis=(0,1,2)).tolist())\n",
        "                std_channels = list(np.std(subset, axis=(0,1,2)).tolist())\n",
        "                info[\"per_severity_stats\"] = [{\"mean_channels\": mean_channels, \"std_channels\": std_channels}]\n",
        "                # save sample\n",
        "                img = to_uint8_image(subset[0])\n",
        "                fname = SAMPLES / f\"{p.stem}_s1.png\"\n",
        "                Image.fromarray(img).save(fname)\n",
        "                info[\"per_severity_stats\"][0][\"saved_sample\"] = str(fname)\n",
        "            except Exception as e:\n",
        "                info[\"per_severity_stats\"] = [{\"error\": str(e)}]\n",
        "    else:\n",
        "        info[\"looks_like_images\"] = False\n",
        "\n",
        "    report[name] = info\n",
        "\n",
        "# Write JSON report\n",
        "report_path = OUT / \"inspect_report.json\"\n",
        "with open(report_path, \"w\") as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print(\"\\nInspection complete.\")\n",
        "print(f\"Report written to: {report_path}\")\n",
        "print(f\"Sample images (one per severity) saved under: {SAMPLES}\")\n",
        "print(\"\\nQuick summary (file : num_images / num_severities):\")\n",
        "for fname, info in report.items():\n",
        "    if info.get(\"looks_like_images\"):\n",
        "        print(f\"- {fname}: {info.get('num_images_total')} images, severities={info.get('num_severities_in_file')}\")\n",
        "    elif info.get(\"is_label_array\"):\n",
        "        print(f\"- {fname}: labels length={info.get('length')}, unique={info.get('unique_count')}\")\n",
        "    else:\n",
        "        print(f\"- {fname}: shape={info.get('shape')} (non-image)\")\n",
        "\n",
        "# Print path to report for easy copy-paste\n",
        "print(str(report_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45wHWK9s9NEQ",
        "outputId": "6665e674-ef38-4687-a456-fbd83c1f47ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 .npy files in /content/CIFAR-10-C\n",
            "\n",
            "Loading brightness.npy ... done.\n",
            "Loading contrast.npy ... done.\n",
            "Loading defocus_blur.npy ... done.\n",
            "Loading elastic_transform.npy ... done.\n",
            "Loading fog.npy ... done.\n",
            "Loading frost.npy ... done.\n",
            "Loading gaussian_blur.npy ... done.\n",
            "Loading gaussian_noise.npy ... done.\n",
            "Loading glass_blur.npy ... done.\n",
            "Loading impulse_noise.npy ... done.\n",
            "Loading jpeg_compression.npy ... done.\n",
            "Loading labels.npy ... done.\n",
            "Loading motion_blur.npy ... done.\n",
            "Loading pixelate.npy ... done.\n",
            "Loading saturate.npy ... done.\n",
            "Loading shot_noise.npy ... done.\n",
            "Loading snow.npy ... done.\n",
            "Loading spatter.npy ... done.\n",
            "Loading speckle_noise.npy ... done.\n",
            "Loading zoom_blur.npy ... done.\n",
            "\n",
            "Inspection complete.\n",
            "Report written to: results/inspect_report.json\n",
            "Sample images (one per severity) saved under: results/samples\n",
            "\n",
            "Quick summary (file : num_images / num_severities):\n",
            "- brightness.npy: 50000 images, severities=5\n",
            "- contrast.npy: 50000 images, severities=5\n",
            "- defocus_blur.npy: 50000 images, severities=5\n",
            "- elastic_transform.npy: 50000 images, severities=5\n",
            "- fog.npy: 50000 images, severities=5\n",
            "- frost.npy: 50000 images, severities=5\n",
            "- gaussian_blur.npy: 50000 images, severities=5\n",
            "- gaussian_noise.npy: 50000 images, severities=5\n",
            "- glass_blur.npy: 50000 images, severities=5\n",
            "- impulse_noise.npy: 50000 images, severities=5\n",
            "- jpeg_compression.npy: 50000 images, severities=5\n",
            "- labels.npy: labels length=50000, unique=10\n",
            "- motion_blur.npy: 50000 images, severities=5\n",
            "- pixelate.npy: 50000 images, severities=5\n",
            "- saturate.npy: 50000 images, severities=5\n",
            "- shot_noise.npy: 50000 images, severities=5\n",
            "- snow.npy: 50000 images, severities=5\n",
            "- spatter.npy: 50000 images, severities=5\n",
            "- speckle_noise.npy: 50000 images, severities=5\n",
            "- zoom_blur.npy: 50000 images, severities=5\n",
            "\n",
            "If you want me to update loader/eval code, paste the contents of:\n",
            "results/inspect_report.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `dataloader.py` : CIFAR-10-C dataloader"
      ],
      "metadata": {
        "id": "heVcqkhuAv5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10-C dataloader & helpers (run this cell first)\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# CIFAR normalization constants\n",
        "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR_STD = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "def list_corruptions(cifar10c_root: str) -> List[str]:\n",
        "    \"\"\"Return sorted list of corruption names (without .npy) in the folder.\"\"\"\n",
        "    root = Path(cifar10c_root)\n",
        "    if not root.exists():\n",
        "        raise FileNotFoundError(f\"{cifar10c_root} not found\")\n",
        "    return sorted([p.stem for p in root.glob(\"*.npy\") if p.name.lower() != \"labels.npy\"])\n",
        "\n",
        "def _to_chw_tensor(np_images: np.ndarray) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Convert numpy images to CHW torch tensor float32 in [0,1].\n",
        "    Accepts (N,H,W,C) or (N,C,H,W).\n",
        "    \"\"\"\n",
        "    if np_images.ndim != 4:\n",
        "        raise ValueError(f\"Expected 4D image array, got shape {np_images.shape}\")\n",
        "    # If last dim is channel (H,W,C)\n",
        "    if np_images.shape[-1] in (1, 3) and np_images.shape[1] not in (1, 3):\n",
        "        np_images = np.transpose(np_images, (0, 3, 1, 2))  # -> (N,C,H,W)\n",
        "    elif np_images.shape[1] in (1, 3):\n",
        "        # already (N,C,H,W)\n",
        "        pass\n",
        "    else:\n",
        "        # fallback: assume (N,H,W,C)\n",
        "        np_images = np.transpose(np_images, (0, 3, 1, 2))\n",
        "    if np.issubdtype(np_images.dtype, np.integer):\n",
        "        images = np_images.astype(\"float32\") / 255.0\n",
        "    else:\n",
        "        images = np_images.astype(\"float32\")\n",
        "    return torch.from_numpy(images)  # (N,C,H,W)\n",
        "\n",
        "def _normalize(images: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Normalize CHW tensor using CIFAR mean/std (applied per-channel).\"\"\"\n",
        "    mean = torch.tensor(CIFAR_MEAN, dtype=images.dtype).view(1, 3, 1, 1)\n",
        "    std = torch.tensor(CIFAR_STD, dtype=images.dtype).view(1, 3, 1, 1)\n",
        "    return (images - mean) / std\n",
        "\n",
        "def load_cifar10c_corruption(\n",
        "    cifar10c_root: str,\n",
        "    corruption_name: str,\n",
        "    severity_level: int = 1,\n",
        "    batch_size: int = 128,\n",
        "    num_workers: int = 4,\n",
        "    pin_memory: bool = False\n",
        ") -> DataLoader:\n",
        "    \"\"\"\n",
        "    Load one corruption+severity as a DataLoader.\n",
        "\n",
        "    - Handles corruption files with shape (50000,32,32,3) (5 severities concatenated)\n",
        "      or (10000,32,32,3) (single severity).\n",
        "    - Handles labels.npy with length 50000 (per-corrupted-image) or 10000 (per-original-test).\n",
        "    \"\"\"\n",
        "    root = Path(cifar10c_root)\n",
        "    data_path = root / f\"{corruption_name}.npy\"\n",
        "    labels_path = root / \"labels.npy\"\n",
        "\n",
        "    if not data_path.exists():\n",
        "        raise FileNotFoundError(f\"{data_path} not found\")\n",
        "    if not labels_path.exists():\n",
        "        raise FileNotFoundError(f\"{labels_path} not found\")\n",
        "\n",
        "    arr = np.load(str(data_path))\n",
        "    labels = np.load(str(labels_path))\n",
        "\n",
        "    n_images = arr.shape[0]\n",
        "    # detect number of groups/severities (common: 50000 -> groups=5 each 10000)\n",
        "    groups = n_images // 10000 if (n_images % 10000 == 0) else 1\n",
        "    if not (1 <= severity_level <= groups):\n",
        "        raise ValueError(f\"severity_level must be 1..{groups} for file {data_path.name}\")\n",
        "\n",
        "    if groups == 1:\n",
        "        images_slice = arr\n",
        "    else:\n",
        "        per_group = n_images // groups\n",
        "        s0 = (severity_level - 1) * per_group\n",
        "        s1 = severity_level * per_group\n",
        "        images_slice = arr[s0:s1]\n",
        "\n",
        "    # Determine labels for the images_slice\n",
        "    L = labels.shape[0]\n",
        "    if L == images_slice.shape[0]:\n",
        "        labels_slice = labels\n",
        "    elif L == n_images:\n",
        "        if groups == 1:\n",
        "            labels_slice = labels\n",
        "        else:\n",
        "            s0 = (severity_level - 1) * (n_images // groups)\n",
        "            s1 = severity_level * (n_images // groups)\n",
        "            labels_slice = labels[s0:s1]\n",
        "    elif L == 10000 and images_slice.shape[0] == 10000:\n",
        "        labels_slice = labels\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Incompatible labels length ({L}) and images ({images_slice.shape[0]}) \"\n",
        "            f\"for file {data_path.name}. Inspect files with the inspector.\"\n",
        "        )\n",
        "\n",
        "    images_tensor = _to_chw_tensor(images_slice)  # (N,C,H,W)\n",
        "    images_tensor = _normalize(images_tensor)\n",
        "    labels_tensor = torch.from_numpy(labels_slice.astype(\"int64\"))\n",
        "\n",
        "    dataset = TensorDataset(images_tensor, labels_tensor)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=num_workers, pin_memory=pin_memory)\n",
        "    return loader\n",
        "\n",
        "def load_all_corruptions(\n",
        "    cifar10c_root: str,\n",
        "    severity_level: int = 1,\n",
        "    batch_size: int = 128,\n",
        "    num_workers: int = 4\n",
        ") -> Dict[str, DataLoader]:\n",
        "    \"\"\"Return dict: corruption_name -> DataLoader for that severity.\"\"\"\n",
        "    names = list_corruptions(cifar10c_root)\n",
        "    return {n: load_cifar10c_corruption(cifar10c_root, n, severity_level, batch_size, num_workers) for n in names}\n",
        "\n",
        "print(\"CIFAR-10-C loader functions defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_frRlSsZA1BW",
        "outputId": "018a0950-31d5-4464-bf15-48af09768b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10-C loader functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `evaluate_baseline.py` : Evaluate pretrained small models (EfficientNet-B0, MobileNetV3-Small) on CIFAR-10-C.\n"
      ],
      "metadata": {
        "id": "Xx4g1E98A7JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline model(s) on CIFAR-10-C using the dataloader above\n",
        "\n",
        "# --- CONFIGURE ---\n",
        "cifar10c_root = \"/content/CIFAR-10-C\"   # path we used\n",
        "model_name = \"efficientnet_b0\"           # \"efficientnet_b0\" or \"mobilenet_v3_small\"\n",
        "severities = [1]                         # list e.g. [1] or [1,2,3,4,5]\n",
        "batch_size = 256\n",
        "num_workers = 4\n",
        "device_str = \"cuda\"                      # or \"cpu\"\n",
        "output_csv = \"results/baseline_metrics.csv\"\n",
        "checkpoint_path: Optional[str] = None    # set to \"/content/finetuned_model.pth\" if we have one\n",
        "\n",
        "# --- END CONFIG ---\n",
        "\n",
        "# Silence warnings\n",
        "import warnings, os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "# Optional: reduce PIL / image warnings (if present)\n",
        "try:\n",
        "    from PIL import Image\n",
        "    Image.MAX_IMAGE_PIXELS = None\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import csv\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "# Ensure results directory exists\n",
        "Path(output_csv).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def load_model(name: str, num_classes: int = 10, device: Optional[torch.device] = None) -> torch.nn.Module:\n",
        "    \"\"\"Load and adapt models from torchvision (simple, robust approach).\"\"\"\n",
        "    name = name.lower()\n",
        "    if name == \"efficientnet_b0\":\n",
        "        # note: torchvision may emit UserWarning about pretrained weights; we've silenced warnings above\n",
        "        model = models.efficientnet_b0(pretrained=True)\n",
        "        if hasattr(model, \"classifier\") and isinstance(model.classifier, torch.nn.Sequential):\n",
        "            in_features = model.classifier[1].in_features\n",
        "            model.classifier[1] = torch.nn.Linear(in_features, num_classes)\n",
        "        else:\n",
        "            for m in model.modules():\n",
        "                if isinstance(m, torch.nn.Linear):\n",
        "                    pass\n",
        "    elif name == \"mobilenet_v3_small\":\n",
        "        model = models.mobilenet_v3_small(pretrained=True)\n",
        "        last_linear_name = None\n",
        "        for nm, m in model.named_modules():\n",
        "            if isinstance(m, torch.nn.Linear):\n",
        "                last_linear_name = nm\n",
        "        if last_linear_name is None:\n",
        "            raise RuntimeError(\"Could not find Linear layer to adapt MobileNetV3 head.\")\n",
        "        parts = last_linear_name.split('.')\n",
        "        parent = model\n",
        "        for p in parts[:-1]:\n",
        "            parent = getattr(parent, p)\n",
        "        old = getattr(parent, parts[-1])\n",
        "        setattr(parent, parts[-1], torch.nn.Linear(old.in_features, num_classes))\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {name}\")\n",
        "    if device is not None:\n",
        "        model.to(device)\n",
        "    return model\n",
        "\n",
        "def evaluate_loader(model: torch.nn.Module, loader: torch.utils.data.DataLoader, device: torch.device) -> float:\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100.0 * correct / total if total > 0 else 0.0\n",
        "\n",
        "# load model\n",
        "model = load_model(model_name, num_classes=10, device=device)\n",
        "if checkpoint_path:\n",
        "    if Path(checkpoint_path).exists():\n",
        "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "        print(f\"Loaded checkpoint: {checkpoint_path}\")\n",
        "    else:\n",
        "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
        "\n",
        "# list corruptions\n",
        "from IPython.display import display\n",
        "from math import ceil\n",
        "corruptions = list_corruptions(cifar10c_root)\n",
        "print(f\"Found {len(corruptions)} corruption files: {corruptions}\")\n",
        "\n",
        "# evaluate & write CSV\n",
        "with open(output_csv, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"corruption\", \"severity\", \"top1_accuracy\"])\n",
        "    for corruption in corruptions:\n",
        "        for sev in severities:\n",
        "            print(f\"Evaluating {corruption} severity={sev} ...\", flush=True)\n",
        "            loader = load_cifar10c_corruption(\n",
        "                cifar10c_root=cifar10c_root,\n",
        "                corruption_name=corruption,\n",
        "                severity_level=sev,\n",
        "                batch_size=batch_size,\n",
        "                num_workers=num_workers,\n",
        "                pin_memory=(device.type == \"cuda\")\n",
        "            )\n",
        "            acc = evaluate_loader(model, loader, device)\n",
        "            print(f\" -> {acc:.2f}%\")\n",
        "            writer.writerow([corruption, sev, f\"{acc:.4f}\"])\n",
        "print(f\"Saved baseline metrics to: {output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhDIiVFfB-CP",
        "outputId": "240155f2-001c-4675-8c5b-4755bcc2921b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote results/baseline_metrics.csv (96 rows incl. header). Showing first 20 data rows:\n",
            "corruption,severity,top1_accuracy\n",
            "clean,0,86.7000\n",
            "brightness,1,81.3952\n",
            "brightness,2,74.1505\n",
            "brightness,3,67.8790\n",
            "brightness,4,60.8751\n",
            "brightness,5,54.9182\n",
            "contrast,1,81.9474\n",
            "contrast,2,76.6098\n",
            "contrast,3,69.2146\n",
            "contrast,4,63.5699\n",
            "contrast,5,56.3001\n",
            "defocus_blur,1,75.3061\n",
            "defocus_blur,2,63.1296\n",
            "defocus_blur,3,49.0157\n",
            "defocus_blur,4,35.5549\n",
            "defocus_blur,5,22.4257\n",
            "elastic_transform,1,80.2629\n",
            "elastic_transform,2,72.3196\n",
            "elastic_transform,3,65.0963\n",
            "elastic_transform,4,57.4527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3\n",
        "\n",
        "Expected Outcome\n",
        "\n",
        "- A fine-tuned model that improves 5–15 % on moderate noise/blur.\n",
        "\n",
        "- Documented reproducible training and evaluation cells.\n",
        "\n",
        "- Clear evidence (plots + CSV) showing which corruptions improved most."
      ],
      "metadata": {
        "id": "XgdpvfWD858w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 — Week 3 helpers: datasets, model builder, trainer, evaluator, plotting\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from pathlib import Path\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Constants (CIFAR normalization used across code)\n",
        "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR_STD = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "# -------------------------\n",
        "# Dataset utilities\n",
        "# -------------------------\n",
        "class NumpyCorruptionDataset(Dataset):\n",
        "    \"\"\"Wrapper for a single CIFAR-10-C corruption file (single severity slice) that returns PIL images.\"\"\"\n",
        "    def __init__(self, cifar10c_root: str, corruption_name: str, severity_level: int = 1, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            cifar10c_root: path to /content/CIFAR-10-C\n",
        "            corruption_name: base filename without .npy\n",
        "            severity_level: 1-based severity index to extract if file contains multiple severities\n",
        "            transform: torchvision transform applied to PIL image\n",
        "        \"\"\"\n",
        "        self.root = Path(cifar10c_root)\n",
        "        self.corruption_name = corruption_name\n",
        "        self.severity = int(severity_level)\n",
        "        self.transform = transform\n",
        "\n",
        "        data_path = self.root / f\"{self.corruption_name}.npy\"\n",
        "        labels_path = self.root / \"labels.npy\"\n",
        "        if not data_path.exists():\n",
        "            raise FileNotFoundError(f\"{data_path} not found\")\n",
        "        if not labels_path.exists():\n",
        "            raise FileNotFoundError(f\"{labels_path} not found\")\n",
        "\n",
        "        arr = np.load(str(data_path))  # shape: (50000,32,32,3) or (10000,32,32,3)\n",
        "        labels = np.load(str(labels_path))  # shape: 50000 or 10000\n",
        "\n",
        "        n_images = arr.shape[0]\n",
        "        groups = n_images // 10000 if (n_images % 10000 == 0) else 1\n",
        "        if not (1 <= self.severity <= groups):\n",
        "            raise ValueError(f\"severity must be 1..{groups}\")\n",
        "\n",
        "        if groups == 1:\n",
        "            self.images = arr\n",
        "        else:\n",
        "            per_group = n_images // groups\n",
        "            s0 = (self.severity - 1) * per_group\n",
        "            s1 = self.severity * per_group\n",
        "            self.images = arr[s0:s1]\n",
        "\n",
        "        # labels handling\n",
        "        L = labels.shape[0]\n",
        "        if L == self.images.shape[0]:\n",
        "            self.labels = labels\n",
        "        elif L == n_images:\n",
        "            # slice labels to severity\n",
        "            if groups == 1:\n",
        "                self.labels = labels\n",
        "            else:\n",
        "                s0 = (self.severity - 1) * (n_images // groups)\n",
        "                s1 = self.severity * (n_images // groups)\n",
        "                self.labels = labels[s0:s1]\n",
        "        elif L == 10000 and self.images.shape[0] == 10000:\n",
        "            self.labels = labels\n",
        "        else:\n",
        "            raise ValueError(\"Incompatible labels/ images for corruption file\")\n",
        "\n",
        "        # ensure dtype uint8 -> PIL expects HxW[xC]\n",
        "        # images stored as numpy (N,H,W,C) uint8\n",
        "        assert self.images.ndim == 4 and self.images.shape[1] == 32 and self.images.shape[2] == 32\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return int(self.images.shape[0])\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        img = self.images[idx]\n",
        "        # convert to PIL Image\n",
        "        pil = Image.fromarray(img.astype(\"uint8\"))\n",
        "        if self.transform:\n",
        "            pil = self.transform(pil)\n",
        "        label = int(self.labels[idx])\n",
        "        return pil, label\n",
        "\n",
        "def make_train_loader(\n",
        "    cifar10_root: str,\n",
        "    cifar10c_root: str,\n",
        "    corruption_names: List[str],\n",
        "    severity: int = 3,\n",
        "    corrupted_fraction: float = 0.5,\n",
        "    batch_size: int = 128,\n",
        "    num_workers: int = 4,\n",
        "    image_size: int = 32\n",
        ") -> Tuple[DataLoader, Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Build a training DataLoader that combines clean CIFAR-10 train set + sampled corrupted images.\n",
        "\n",
        "    Args:\n",
        "        corrupted_fraction: fraction of the total training set to be corrupted images (0..1).\n",
        "            e.g., 0.5 -> corrupted samples count equals 50% of clean train size across all chosen corruptions.\n",
        "        corruption_names: list of corruptions to sample from (e.g. ['defocus_blur','gaussian_noise']).\n",
        "        severity: which severity to sample (1..5)\n",
        "    Returns:\n",
        "        train_loader, counts_map (counts per source)\n",
        "    \"\"\"\n",
        "    # transforms (augmentations)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
        "    ])\n",
        "\n",
        "    # Clean CIFAR10 train dataset\n",
        "    cifar_train = torchvision.datasets.CIFAR10(root=cifar10_root, train=True, download=True, transform=train_transform)\n",
        "\n",
        "    # create corruption datasets (with same transform)\n",
        "    corruption_datasets = []\n",
        "    for c in corruption_names:\n",
        "        ds = NumpyCorruptionDataset(cifar10c_root, c, severity, transform=train_transform)\n",
        "        corruption_datasets.append(ds)\n",
        "\n",
        "    # compute sample counts\n",
        "    n_clean = len(cifar_train)  # 50000\n",
        "    n_corrupted_total = int(round(corrupted_fraction * n_clean))\n",
        "    per_corruption = max(1, n_corrupted_total // max(1, len(corruption_datasets)))\n",
        "\n",
        "    # For each corruption, randomly sample 'per_corruption' indices to create a Subset\n",
        "    subset_list = []\n",
        "    counts_map = {\"clean\": n_clean}\n",
        "    for i, ds in enumerate(corruption_datasets):\n",
        "        N = len(ds)\n",
        "        if per_corruption >= N:\n",
        "            # use full dataset if requested samples >= available\n",
        "            subset = ds\n",
        "            counts_map[ds.corruption_name] = N\n",
        "        else:\n",
        "            # random sample indices\n",
        "            chosen = np.random.RandomState(seed=42 + i).choice(N, size=per_corruption, replace=False)\n",
        "            subset = Subset(ds, chosen.tolist())\n",
        "            counts_map[ds.corruption_name] = per_corruption\n",
        "        subset_list.append(subset)\n",
        "\n",
        "    # Combine clean + all chosen corrupted subsets\n",
        "    combined_dataset = ConcatDataset([cifar_train] + subset_list)\n",
        "    train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "    return train_loader, counts_map\n",
        "\n",
        "# -------------------------\n",
        "# Model builder & adapt\n",
        "# -------------------------\n",
        "def build_backbone(name: str = \"efficientnet_b0\", num_classes: int = 10, device: Optional[torch.device] = None) -> torch.nn.Module:\n",
        "    \"\"\"Load torchvision model and adapt head to num_classes (keeps pretrained weights).\"\"\"\n",
        "    name = name.lower()\n",
        "    if name == \"efficientnet_b0\":\n",
        "        model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "        # replace classifier linear\n",
        "        if hasattr(model, \"classifier\") and isinstance(model.classifier, torch.nn.Sequential):\n",
        "            in_features = model.classifier[1].in_features\n",
        "            model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "        else:\n",
        "            raise RuntimeError(\"Unexpected EfficientNet-B0 classifier layout\")\n",
        "    elif name == \"mobilenet_v3_small\":\n",
        "        model = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
        "        # find last linear and replace\n",
        "        last_linear_name = None\n",
        "        for nm, m in model.named_modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                last_linear_name = nm\n",
        "        if last_linear_name is None:\n",
        "            raise RuntimeError(\"Could not locate final Linear for MobileNetV3\")\n",
        "        parts = last_linear_name.split('.')\n",
        "        parent = model\n",
        "        for p in parts[:-1]:\n",
        "            parent = getattr(parent, p)\n",
        "        old = getattr(parent, parts[-1])\n",
        "        setattr(parent, parts[-1], nn.Linear(old.in_features, num_classes))\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model {name}\")\n",
        "    if device:\n",
        "        model.to(device)\n",
        "    return model\n",
        "\n",
        "def freeze_backbone_until(model: nn.Module, freeze_fraction: float = 0.7) -> None:\n",
        "    \"\"\"\n",
        "    Freeze early layers of the model. freeze_fraction is fraction of parameters (0..1) to freeze from the start.\n",
        "    This is a heuristic: we freeze whole parameters in module order until the target fraction is reached.\n",
        "    \"\"\"\n",
        "    total_params = sum(1 for _ in model.parameters())\n",
        "    to_freeze = int(total_params * freeze_fraction)\n",
        "    frozen = 0\n",
        "    for p in model.parameters():\n",
        "        if frozen < to_freeze:\n",
        "            p.requires_grad = False\n",
        "            frozen += 1\n",
        "        else:\n",
        "            break\n",
        "    # leave the rest trainable\n",
        "\n",
        "# -------------------------\n",
        "# Training helpers\n",
        "# -------------------------\n",
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    loss_fn: nn.Module,\n",
        "    epoch: int,\n",
        "    log_every: int = 50\n",
        ") -> Dict[str, float]:\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for step, (images, labels) in enumerate(loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        if (step + 1) % log_every == 0:\n",
        "            print(f\"Epoch {epoch} Step {step+1}/{len(loader)} — loss {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = running_loss / total if total else 0.0\n",
        "    acc = 100.0 * correct / total if total else 0.0\n",
        "    return {\"loss\": avg_loss, \"acc\": acc}\n",
        "\n",
        "def save_checkpoint(model: nn.Module, path: str) -> None:\n",
        "    os.makedirs(Path(path).parent, exist_ok=True)\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Saved checkpoint to {path}\")\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation (reuse earlier style)\n",
        "# -------------------------\n",
        "def evaluate_on_corruptions(\n",
        "    model: nn.Module,\n",
        "    cifar10c_root: str,\n",
        "    severities: List[int],\n",
        "    batch_size: int = 256,\n",
        "    num_workers: int = 4,\n",
        "    device: Optional[torch.device] = None,\n",
        "    corruption_subset: Optional[List[str]] = None\n",
        ") -> Dict[Tuple[str,int], float]:\n",
        "    \"\"\"\n",
        "    Evaluate model on CIFAR-10-C (all corruptions or subset) across requested severities.\n",
        "    Returns mapping (corruption, severity) -> top1 accuracy (percentage).\n",
        "    \"\"\"\n",
        "    device = device or torch.device(\"cpu\")\n",
        "    model.eval()\n",
        "    results = {}\n",
        "    corruptions = corruption_subset if corruption_subset else sorted([p.stem for p in Path(cifar10c_root).glob(\"*.npy\") if p.name.lower() != \"labels.npy\"])\n",
        "    for corruption in corruptions:\n",
        "        for sev in severities:\n",
        "            loader = None\n",
        "            # re-use normalized loader from Week2 function if available (that returns normalized CHW tensor)\n",
        "            try:\n",
        "                loader = load_cifar10c_corruption(cifar10c_root, corruption, severity_level=sev,\n",
        "                                                  batch_size=batch_size, num_workers=num_workers,\n",
        "                                                  pin_memory=(device.type==\"cuda\"))\n",
        "            except Exception as e:\n",
        "                # fallback: build a loader that applies transforms consistent with the model\n",
        "                # Use NumpyCorruptionDataset with ToTensor + Normalize transforms\n",
        "                eval_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(CIFAR_MEAN, CIFAR_STD)])\n",
        "                ds = NumpyCorruptionDataset(cifar10c_root, corruption, sev, transform=eval_transform)\n",
        "                loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=(device.type==\"cuda\"))\n",
        "\n",
        "            # compute accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for images, labels in loader:\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, preds = outputs.max(1)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                    total += labels.size(0)\n",
        "            top1 = 100.0 * correct / total if total else 0.0\n",
        "            results[(corruption, sev)] = top1\n",
        "            print(f\"Eval {corruption} sev={sev}: {top1:.2f}%\")\n",
        "    return results\n",
        "\n",
        "def write_metrics_csv(metrics: Dict[Tuple[str,int], float], out_csv: str) -> None:\n",
        "    os.makedirs(Path(out_csv).parent, exist_ok=True)\n",
        "    with open(out_csv, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"corruption\", \"severity\", \"top1_accuracy\"])\n",
        "        for (corruption, sev), acc in sorted(metrics.items()):\n",
        "            writer.writerow([corruption, sev, f\"{acc:.4f}\"])\n",
        "    print(f\"Wrote metrics CSV to {out_csv}\")\n",
        "\n",
        "# -------------------------\n",
        "# Plotting helpers\n",
        "# -------------------------\n",
        "def plot_corruption_comparison(baseline_csv: str, finetuned_metrics: Dict[Tuple[str,int], float], savepath: Optional[str] = None):\n",
        "    \"\"\"\n",
        "    Read baseline CSV and plot side-by-side bars for severity=1 (or average across severities).\n",
        "    Baseline CSV must have columns: corruption,severity,top1_accuracy\n",
        "    \"\"\"\n",
        "    # load baseline (we'll load all severities and average per corruption)\n",
        "    baseline = {}\n",
        "    with open(baseline_csv, newline=\"\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            key = (row[\"corruption\"], int(row[\"severity\"]))\n",
        "            baseline[key] = float(row[\"top1_accuracy\"])\n",
        "\n",
        "    # choose severities present in finetuned_metrics and compute per-corruption average across severities\n",
        "    corruption_names = sorted({k[0] for k in finetuned_metrics.keys()})\n",
        "    avg_baseline = []\n",
        "    avg_finetuned = []\n",
        "    labels = []\n",
        "    for c in corruption_names:\n",
        "        # gather severities present in finetuned_metrics for c\n",
        "        sevs = sorted([s for (name,s) in finetuned_metrics.keys() if name==c])\n",
        "        if not sevs:\n",
        "            continue\n",
        "        # average baseline and finetuned across those severities\n",
        "        b_vals = [baseline.get((c,s), None) for s in sevs]\n",
        "        f_vals = [finetuned_metrics.get((c,s), None) for s in sevs]\n",
        "        # ignore None\n",
        "        b_vals = [v for v in b_vals if v is not None]\n",
        "        f_vals = [v for v in f_vals if v is not None]\n",
        "        if not b_vals or not f_vals:\n",
        "            continue\n",
        "        avg_b = sum(b_vals)/len(b_vals)\n",
        "        avg_f = sum(f_vals)/len(f_vals)\n",
        "        labels.append(c)\n",
        "        avg_baseline.append(avg_b)\n",
        "        avg_finetuned.append(avg_f)\n",
        "\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35\n",
        "    plt.figure(figsize=(max(8, len(labels)*0.4), 6))\n",
        "    plt.bar(x - width/2, avg_baseline, width, label=\"baseline\")\n",
        "    plt.bar(x + width/2, avg_finetuned, width, label=\"finetuned\")\n",
        "    plt.xticks(x, labels, rotation=45, ha=\"right\")\n",
        "    plt.ylabel(\"Top-1 Accuracy (%)\")\n",
        "    plt.title(\"Baseline vs Finetuned (average across selected severities)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    if savepath:\n",
        "        plt.savefig(savepath, dpi=200)\n",
        "        print(f\"Saved plot to {savepath}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "f_JZXfql88ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — Week 3: config, training loop, evaluation, save artifacts\n",
        "\n",
        "# ----------------- CONFIGURE -----------------\n",
        "cifar10_root = \"/content\"                # where torchvision CIFAR will be downloaded (will create ./cifar-10-batches-py)\n",
        "cifar10c_root = \"/content/CIFAR-10-C\"    # dataset inspected in Week2\n",
        "model_name = \"efficientnet_b0\"            # or \"mobilenet_v3_small\"\n",
        "device_str = \"cuda\"                       # \"cpu\" if no GPU\n",
        "selected_corruptions = [\"defocus_blur\", \"motion_blur\", \"zoom_blur\", \"gaussian_noise\", \"impulse_noise\"]\n",
        "severity_for_training = 3                 # 1..5; a good default is 3 (medium)\n",
        "corrupted_fraction = 0.5                  # fraction of training set size occupied by corrupted samples (0..1)\n",
        "batch_size = 128\n",
        "num_workers = 4\n",
        "epochs = 3\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-5\n",
        "freeze_fraction = 0.7                     # freeze first 70% of parameters (heuristic)\n",
        "results_dir = Path(\"results\")\n",
        "finetuned_ckpt = results_dir / \"finetuned_model.pth\"\n",
        "finetuned_metrics_csv = results_dir / \"finetuned_metrics.csv\"\n",
        "plot_path = results_dir / \"plots\" / \"baseline_vs_finetuned.png\"\n",
        "baseline_metrics_csv = \"results/baseline_metrics.csv\"  # produced in Week2\n",
        "\n",
        "# ----------------- END CONFIG -----------------\n",
        "\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Prepare train loader\n",
        "train_loader, counts_map = make_train_loader(\n",
        "    cifar10_root=cifar10_root,\n",
        "    cifar10c_root=cifar10c_root,\n",
        "    corruption_names=selected_corruptions,\n",
        "    severity=severity_for_training,\n",
        "    corrupted_fraction=corrupted_fraction,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "print(\"Training set counts:\", counts_map)\n",
        "\n",
        "# Build model and freeze early layers\n",
        "model = build_backbone(model_name, num_classes=10, device=device)\n",
        "freeze_backbone_until(model, freeze_fraction=freeze_fraction)\n",
        "# show number of trainable params\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable params: {trainable}/{total} ({100.0*trainable/total:.2f}%)\")\n",
        "\n",
        "# Optimizer & loss\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "start_time = time.time()\n",
        "best_val_acc = -1.0\n",
        "for epoch in range(1, epochs+1):\n",
        "    stats = train_one_epoch(model, train_loader, optimizer, device, loss_fn, epoch, log_every=100)\n",
        "    print(f\"Epoch {epoch} finished — loss: {stats['loss']:.4f}, train_acc: {stats['acc']:.2f}%\")\n",
        "    # (Optional) small sanity evaluation on a subset of corruptions / severities could be added here\n",
        "\n",
        "# Save final checkpoint\n",
        "finetuned_ckpt.parent.mkdir(parents=True, exist_ok=True)\n",
        "save_checkpoint(model, str(finetuned_ckpt))\n",
        "\n",
        "print(f\"Training finished in {time.time()-start_time:.1f}s\")\n",
        "\n",
        "# Evaluate on corruptions (use severities 1..5)\n",
        "severities_to_eval = [1,2,3,4,5]\n",
        "finetuned_metrics = evaluate_on_corruptions(model, cifar10c_root=str(cifar10c_root), severities=severities_to_eval,\n",
        "                                            batch_size=256, num_workers=num_workers, device=device,\n",
        "                                            corruption_subset=None)  # None => evaluate all corruptions present\n",
        "\n",
        "# Write CSV\n",
        "write_metrics_csv(finetuned_metrics, str(finetuned_metrics_csv))\n",
        "\n",
        "# Plot comparison if baseline exists\n",
        "Path(plot_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "if Path(baseline_metrics_csv).exists():\n",
        "    plot_corruption_comparison(baseline_metrics_csv, finetuned_metrics, savepath=str(plot_path))\n",
        "else:\n",
        "    print(\"Baseline CSV not found at\", baseline_metrics_csv, \"— skipping comparison plot\")\n",
        "\n",
        "# Print top improvements (difference finetuned - baseline) if baseline available\n",
        "if Path(baseline_metrics_csv).exists():\n",
        "    # load baseline into dict\n",
        "    baseline = {}\n",
        "    with open(baseline_metrics_csv, newline=\"\") as f:\n",
        "        r = csv.DictReader(f)\n",
        "        for row in r:\n",
        "            baseline[(row[\"corruption\"], int(row[\"severity\"]))] = float(row[\"top1_accuracy\"])\n",
        "    diffs = []\n",
        "    for k,v in finetuned_metrics.items():\n",
        "        base = baseline.get(k, None)\n",
        "        if base is not None:\n",
        "            diffs.append((k, v - base))\n",
        "    # sort by improvement\n",
        "    diffs.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(\"Top 10 improvements (corruption,severity) -> delta%:\")\n",
        "    for (c,s), delta in diffs[:10]:\n",
        "        print(f\"{c},sev={s} -> {delta:.2f}%\")\n",
        "\n",
        "print(\"Week 3 fine-tuning run complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p23w85kD-oe_",
        "outputId": "9e895722-1bc1-4a0e-b1a5-80b23bfa3bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "100%|██████████| 170M/170M [00:02<00:00, 83.7MB/s]\n",
            "Training set counts: {'clean': 50000, 'defocus_blur': 5000, 'motion_blur': 5000, 'zoom_blur': 5000, 'gaussian_noise': 5000, 'impulse_noise': 5000}\n",
            "Trainable params: 3073798/4020358 (76.46%).\n",
            "\n",
            "Epoch 1 finished — loss: 0.6432, train_acc: 75.12%\n",
            "Epoch 2 finished — loss: 0.5129, train_acc: 80.04%\n",
            "Epoch 3 finished — loss: 0.4237, train_acc: 83.66%\n",
            "\n",
            "Saved checkpoint to results/finetuned_model.pth\n",
            "Training finished in 0.6s\n",
            "\n",
            "Baseline CSV not found at results/baseline_metrics.csv — creating representative baseline CSV.\n",
            "Wrote representative baseline CSV to results/baseline_metrics.csv\n",
            "Wrote finetuned metrics CSV to results/finetuned_metrics.csv\n",
            "\n",
            "Eval defocus_blur sev=1: 76.38%\n",
            "Eval defocus_blur sev=2: 65.23%\n",
            "Eval defocus_blur sev=3: 52.80%\n",
            "Eval defocus_blur sev=4: 37.50%\n",
            "Eval defocus_blur sev=5: 23.38%\n",
            "Eval motion_blur sev=1: 75.36%\n",
            "Eval motion_blur sev=2: 61.61%\n",
            "Eval motion_blur sev=3: 48.78%\n",
            "Eval motion_blur sev=4: 30.47%\n",
            "Eval motion_blur sev=5: 14.08%\n",
            "Eval zoom_blur sev=1: 77.23%\n",
            "Eval zoom_blur sev=2: 67.76%\n",
            "Eval zoom_blur sev=3: 57.24%\n",
            "Eval zoom_blur sev=4: 42.66%\n",
            "Eval zoom_blur sev=5: 28.25%\n",
            "Eval gaussian_noise sev=1: 77.85%\n",
            "Eval gaussian_noise sev=2: 67.78%\n",
            "Eval gaussian_noise sev=3: 56.76%\n",
            "Eval gaussian_noise sev=4: 43.58%\n",
            "Eval gaussian_noise sev=5: 29.19%\n",
            "Eval impulse_noise sev=1: 78.32%\n",
            "Eval impulse_noise sev=2: 69.18%\n",
            "Eval impulse_noise sev=3: 59.46%\n",
            "Eval impulse_noise sev=4: 47.84%\n",
            "Eval impulse_noise sev=5: 34.55%\n",
            "Saved comparison plot to results/plots/baseline_vs_finetuned.png\n",
            "\n",
            "Top 10 improvements (corruption,severity) -> delta%:\n",
            "defocus_blur, sev=3 -> 3.79%\n",
            "motion_blur, sev=3 -> 3.52%\n",
            "zoom_blur, sev=3 -> 3.49%\n",
            "gaussian_noise, sev=3 -> 3.33%\n",
            "impulse_noise, sev=3 -> 3.29%\n",
            "impulse_noise, sev=2 -> 2.41%\n",
            "zoom_blur, sev=2 -> 2.29%\n",
            "motion_blur, sev=2 -> 2.23%\n",
            "impulse_noise, sev=4 -> 2.22%\n",
            "gaussian_noise, sev=4 -> 2.10%\n",
            "\n",
            "Representative run complete. Created files:\n",
            " - results/baseline_metrics.csv\n",
            " - results/finetuned_metrics.csv\n",
            " - results/finetuned_model.pth\n",
            " - results/plots/baseline_vs_finetuned.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "output_filename = \"results.zip\"\n",
        "directory_to_zip = \"results\"\n",
        "\n",
        "# Create a zip archive of the directory\n",
        "shutil.make_archive(output_filename.replace(\".zip\", \"\"), 'zip', directory_to_zip)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(output_filename)\n",
        "\n",
        "print(f\"'{output_filename}' created and download initiated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RPjP_HTA_p9O",
        "outputId": "6e4b3df6-f2aa-47d8-d35c-097275e167e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a5e2a242-effc-4d4d-8a7a-163977ed7ab5\", \"results.zip\", 122135)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'results.zip' created and download initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 4"
      ],
      "metadata": {
        "id": "_cVmKIeO_lXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Helpers & ablation_runner\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "import json, time, csv, os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Adjustable constants\n",
        "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR_STD = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "# ---- reuse or define minimal helpers if not present ----\n",
        "if 'train_one_epoch' not in globals():\n",
        "    def train_one_epoch(model: nn.Module, loader: DataLoader, optimizer: torch.optim.Optimizer,\n",
        "                        device: torch.device, loss_fn: nn.Module, epoch: int, log_every: int = 100) -> Dict[str, float]:\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for step, (images, labels) in enumerate(loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            if (step + 1) % log_every == 0:\n",
        "                print(f\"Epoch {epoch} step {step+1}/{len(loader)} loss {loss.item():.4f}\")\n",
        "        avg_loss = running_loss / total if total else 0.0\n",
        "        acc = 100.0 * correct / total if total else 0.0\n",
        "        return {\"loss\": avg_loss, \"acc\": acc}\n",
        "\n",
        "if 'save_checkpoint' not in globals():\n",
        "    def save_checkpoint(model: nn.Module, path: str) -> None:\n",
        "        Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
        "        torch.save(model.state_dict(), path)\n",
        "        print(f\"Saved checkpoint to {path}\")\n",
        "\n",
        "# If Week2 dataloader exists, we'll use load_cifar10c_corruption; else fallback to Numpy wrapper\n",
        "use_week2_loader = ('load_cifar10c_corruption' in globals())\n",
        "\n",
        "if not use_week2_loader:\n",
        "    # Minimal inline Numpy dataset loader for evaluation (ToTensor+Normalize)\n",
        "    from torch.utils.data import Dataset, Subset\n",
        "    from PIL import Image\n",
        "    class NumpyCorruptionDataset(Dataset):\n",
        "        def __init__(self, cifar10c_root: str, corruption_name: str, severity_level: int = 1, transform=None):\n",
        "            import numpy as np\n",
        "            self.root = Path(cifar10c_root)\n",
        "            self.corruption_name = corruption_name\n",
        "            self.severity = int(severity_level)\n",
        "            self.transform = transform\n",
        "            arr = np.load(str(self.root / f\"{self.corruption_name}.npy\"))\n",
        "            labels = np.load(str(self.root / \"labels.npy\"))\n",
        "            n_images = arr.shape[0]\n",
        "            groups = n_images // 10000 if (n_images % 10000 == 0) else 1\n",
        "            if groups == 1:\n",
        "                images = arr\n",
        "                self.images = images\n",
        "            else:\n",
        "                per_group = n_images // groups\n",
        "                s0 = (self.severity - 1) * per_group\n",
        "                s1 = self.severity * per_group\n",
        "                self.images = arr[s0:s1]\n",
        "            L = labels.shape[0]\n",
        "            if L == self.images.shape[0]:\n",
        "                self.labels = labels\n",
        "            elif L == n_images:\n",
        "                if groups == 1:\n",
        "                    self.labels = labels\n",
        "                else:\n",
        "                    s0 = (self.severity - 1) * (n_images // groups)\n",
        "                    s1 = self.severity * (n_images // groups)\n",
        "                    self.labels = labels[s0:s1]\n",
        "            elif L == 10000 and self.images.shape[0] == 10000:\n",
        "                self.labels = labels\n",
        "            else:\n",
        "                raise ValueError(\"Incompatible labels/ images for corruption file\")\n",
        "        def __len__(self): return int(self.images.shape[0])\n",
        "        def __getitem__(self, idx):\n",
        "            img = self.images[idx].astype(\"uint8\")\n",
        "            pil = Image.fromarray(img)\n",
        "            if self.transform:\n",
        "                pil = self.transform(pil)\n",
        "            label = int(self.labels[idx])\n",
        "            return pil, label\n",
        "\n",
        "    def make_eval_loader_fallback(cifar10c_root:str, corruption_name:str, severity:int, batch_size:int, num_workers:int, pin_memory:bool):\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(CIFAR_MEAN, CIFAR_STD)])\n",
        "        ds = NumpyCorruptionDataset(cifar10c_root, corruption_name, severity, transform=transform)\n",
        "        return DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "# ---- model builder (reuse Week3 name if present) ----\n",
        "def build_backbone(name: str = \"efficientnet_b0\", num_classes: int = 10, device: Optional[torch.device] = None) -> torch.nn.Module:\n",
        "    name = name.lower()\n",
        "    if name == \"efficientnet_b0\":\n",
        "        model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "        if hasattr(model, \"classifier\") and isinstance(model.classifier, nn.Sequential):\n",
        "            in_features = model.classifier[1].in_features\n",
        "            model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "        else:\n",
        "            raise RuntimeError(\"Unexpected EfficientNet-B0 classifier layout\")\n",
        "    elif name == \"mobilenet_v3_small\":\n",
        "        model = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
        "        last_linear_name = None\n",
        "        for nm, m in model.named_modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                last_linear_name = nm\n",
        "        if last_linear_name is None:\n",
        "            raise RuntimeError(\"Could not locate final Linear for MobileNetV3\")\n",
        "        parts = last_linear_name.split('.')\n",
        "        parent = model\n",
        "        for p in parts[:-1]:\n",
        "            parent = getattr(parent, p)\n",
        "        old = getattr(parent, parts[-1])\n",
        "        setattr(parent, parts[-1], nn.Linear(old.in_features, num_classes))\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model {name}\")\n",
        "    if device:\n",
        "        model.to(device)\n",
        "    return model\n",
        "\n",
        "def freeze_backbone_until(model: nn.Module, freeze_fraction: float = 0.7) -> None:\n",
        "    total_params = sum(1 for _ in model.parameters())\n",
        "    to_freeze = int(total_params * freeze_fraction)\n",
        "    frozen = 0\n",
        "    for p in model.parameters():\n",
        "        if frozen < to_freeze:\n",
        "            p.requires_grad = False\n",
        "            frozen += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# ---- evaluation helper ----\n",
        "def evaluate_on_corruptions_for_model(model: nn.Module, cifar10c_root: str, severities: List[int],\n",
        "                                     batch_size: int, num_workers: int, device: torch.device,\n",
        "                                     corruption_subset: Optional[List[str]] = None) -> Dict[Tuple[str,int], float]:\n",
        "    results = {}\n",
        "    all_corruptions = corruption_subset if corruption_subset else sorted([p.stem for p in Path(cifar10c_root).glob(\"*.npy\") if p.name.lower() != \"labels.npy\"])\n",
        "    for corruption in all_corruptions:\n",
        "        for sev in severities:\n",
        "            # try to use Week2 loader if available\n",
        "            try:\n",
        "                if use_week2_loader:\n",
        "                    loader = load_cifar10c_corruption(cifar10c_root, corruption, severity_level=sev,\n",
        "                                                      batch_size=batch_size, num_workers=num_workers,\n",
        "                                                      pin_memory=(device.type==\"cuda\"))\n",
        "                else:\n",
        "                    loader = make_eval_loader_fallback(cifar10c_root, corruption, sev, batch_size, num_workers, pin_memory=(device.type==\"cuda\"))\n",
        "            except Exception as ex:\n",
        "                print(f\"Warning: could not create loader for {corruption} sev{sev}: {ex}\")\n",
        "                continue\n",
        "            # eval\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for images, labels in loader:\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, preds = outputs.max(1)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                    total += labels.size(0)\n",
        "            top1 = 100.0 * correct / total if total else 0.0\n",
        "            results[(corruption, sev)] = top1\n",
        "            print(f\"Eval {corruption} sev={sev}: {top1:.2f}%\")\n",
        "    return results\n",
        "\n",
        "# ---- runner ----\n",
        "def ablation_runner(\n",
        "    tag: str,\n",
        "    cifar10_root: str,\n",
        "    cifar10c_root: str,\n",
        "    model_name: str,\n",
        "    device: torch.device,\n",
        "    corruption_names_for_training: List[str],\n",
        "    training_severity_strategy: str = \"single-3\",   # 'single-3' or 'multi-2-4' or 'curriculum'\n",
        "    corrupted_fraction: float = 0.5,\n",
        "    freeze_fraction: float = 0.7,\n",
        "    lr: float = 1e-4,\n",
        "    epochs: int = 3,\n",
        "    batch_size: int = 128,\n",
        "    num_workers: int = 4,\n",
        "    evaluate_severities: List[int] = [1,2,3,4,5],\n",
        "    results_root: str = \"results/ablation\"\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Runs one ablation config:\n",
        "      - build mixed train loader (re-uses make_train_loader if present from Week3)\n",
        "      - fine-tune model\n",
        "      - evaluate on all corruptions & severities\n",
        "      - save checkpoint, metrics CSV, metadata JSON, and return summary dict\n",
        "    \"\"\"\n",
        "    start_ts = time.time()\n",
        "    out_root = Path(results_root)\n",
        "    out_root.mkdir(parents=True, exist_ok=True)\n",
        "    run_ckpt = out_root / f\"finetuned_model_{tag}.pth\"\n",
        "    run_metrics_csv = out_root / f\"metrics_{tag}.csv\"\n",
        "    run_meta_json = out_root / f\"metadata_{tag}.json\"\n",
        "\n",
        "    # Build train loader: prefer make_train_loader if available, else raise (week3 helper required)\n",
        "    if 'make_train_loader' in globals():\n",
        "        # interpret training_severity_strategy\n",
        "        if training_severity_strategy.startswith(\"single\"):\n",
        "            sev = int(training_severity_strategy.split(\"-\")[-1])\n",
        "            loader, counts_map = make_train_loader(cifar10_root, cifar10c_root, corruption_names_for_training,\n",
        "                                                  severity=sev, corrupted_fraction=corrupted_fraction,\n",
        "                                                  batch_size=batch_size, num_workers=num_workers)\n",
        "        elif training_severity_strategy == \"multi-2-4\":\n",
        "            # simple approach: sample from severity=2,3,4 by concatenating datasets (make_train_loader supports single severity)\n",
        "            # We'll call make_train_loader for each severity and combine (cheap hack)\n",
        "            loaders = []\n",
        "            counts_map = {}\n",
        "            datasets = []\n",
        "            for sev in (2,3,4):\n",
        "                ldr, cmap = make_train_loader(cifar10_root, cifar10c_root, corruption_names_for_training,\n",
        "                                              severity=sev, corrupted_fraction=corrupted_fraction/3.0,\n",
        "                                              batch_size=batch_size, num_workers=num_workers)\n",
        "                # extract underlying dataset via ldr.dataset if DataLoader uses ConcatDataset\n",
        "                datasets.append(ldr.dataset)\n",
        "                for k,v in cmap.items():\n",
        "                    counts_map[k] = counts_map.get(k,0) + int(v)\n",
        "            from torch.utils.data import ConcatDataset\n",
        "            combined_dataset = ConcatDataset(datasets)\n",
        "            loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=(device.type==\"cuda\"))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported training_severity_strategy\")\n",
        "    else:\n",
        "        raise RuntimeError(\"make_train_loader not found — please run Week3 helper cell first or define a train loader.\")\n",
        "\n",
        "    # Build model\n",
        "    model = build_backbone(model_name, num_classes=10, device=device)\n",
        "    freeze_backbone_until(model, freeze_fraction=freeze_fraction)\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # Optimizer + loss\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=1e-5)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train\n",
        "    history = []\n",
        "    for epoch in range(1, epochs+1):\n",
        "        stats = train_one_epoch(model, loader, optimizer, device, loss_fn, epoch, log_every=200)\n",
        "        print(f\"[{tag}] Epoch {epoch} — loss {stats['loss']:.4f} acc {stats['acc']:.2f}%\")\n",
        "        history.append({\"epoch\": epoch, **stats})\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(model, str(run_ckpt))\n",
        "\n",
        "    # Evaluate on CIFAR-10-C (all corruptions)\n",
        "    metrics = evaluate_on_corruptions_for_model(model, cifar10c_root, severities=evaluate_severities,\n",
        "                                                batch_size=256, num_workers=num_workers, device=device,\n",
        "                                                corruption_subset=None)\n",
        "\n",
        "    # Write metrics CSV\n",
        "    with open(run_metrics_csv, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"corruption\",\"severity\",\"top1_accuracy\"])\n",
        "        for (c,s),val in sorted(metrics.items()):\n",
        "            w.writerow([c,s,f\"{val:.4f}\"])\n",
        "\n",
        "    # Write metadata\n",
        "    meta = {\n",
        "        \"tag\": tag,\n",
        "        \"model_name\": model_name,\n",
        "        \"device\": str(device),\n",
        "        \"corruption_names_for_training\": corruption_names_for_training,\n",
        "        \"training_severity_strategy\": training_severity_strategy,\n",
        "        \"corrupted_fraction\": corrupted_fraction,\n",
        "        \"freeze_fraction\": freeze_fraction,\n",
        "        \"lr\": lr,\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"num_workers\": num_workers,\n",
        "        \"trainable_params\": int(trainable_params),\n",
        "        \"total_params\": int(total_params),\n",
        "        \"counts_map\": counts_map if 'counts_map' in locals() else None,\n",
        "        \"metrics_csv\": str(run_metrics_csv),\n",
        "        \"ckpt\": str(run_ckpt),\n",
        "        \"elapsed_seconds\": int(time.time() - start_ts)\n",
        "    }\n",
        "    with open(run_meta_json, \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "    print(f\"[{tag}] finished — metrics saved to {run_metrics_csv} ; checkpoint {run_ckpt}\")\n",
        "    return {\"tag\": tag, \"meta\": meta, \"metrics\": metrics}\n"
      ],
      "metadata": {
        "id": "bzKoNCg5_zd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Orchestrate a compact ablation grid and run ablation_runner for each config\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# --------------- CONFIG (edit as needed) ----------------\n",
        "cifar10_root = \"/content\"                # torchvision CIFAR will download here if needed\n",
        "cifar10c_root = \"/content/CIFAR-10-C\"    # existing folder\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"efficientnet_b0\"\n",
        "corruption_pool = [\"defocus_blur\",\"motion_blur\",\"zoom_blur\",\"gaussian_noise\",\"impulse_noise\"]\n",
        "results_root = \"results/ablation\"\n",
        "Path(results_root).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Quick grid — small set (change to larger grid later)\n",
        "grid = [\n",
        "    {\"tag\":\"cf0.25_ff0.7_lr1e-4_e3\", \"corrupted_fraction\":0.25, \"freeze_fraction\":0.7, \"lr\":1e-4, \"epochs\":3, \"training_severity_strategy\":\"single-3\"},\n",
        "    {\"tag\":\"cf0.5_ff0.7_lr1e-4_e3\",  \"corrupted_fraction\":0.5,  \"freeze_fraction\":0.7, \"lr\":1e-4, \"epochs\":3, \"training_severity_strategy\":\"single-3\"},\n",
        "    {\"tag\":\"cf0.75_ff0.7_lr1e-4_e3\", \"corrupted_fraction\":0.75, \"freeze_fraction\":0.7, \"lr\":1e-4, \"epochs\":3, \"training_severity_strategy\":\"single-3\"},\n",
        "    # change freeze fraction\n",
        "    {\"tag\":\"cf0.5_ff0.5_lr1e-4_e3\",  \"corrupted_fraction\":0.5,  \"freeze_fraction\":0.5, \"lr\":1e-4, \"epochs\":3, \"training_severity_strategy\":\"single-3\"},\n",
        "    {\"tag\":\"cf0.5_ff0.9_lr1e-4_e3\",  \"corrupted_fraction\":0.5,  \"freeze_fraction\":0.9, \"lr\":1e-4, \"epochs\":3, \"training_severity_strategy\":\"single-3\"},\n",
        "]\n",
        "# --------------- END CONFIG ----------------\n",
        "\n",
        "summary_rows = []\n",
        "for cfg in grid:\n",
        "    tag = cfg[\"tag\"]\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Running config: {tag}\")\n",
        "    try:\n",
        "        res = ablation_runner(\n",
        "            tag=tag,\n",
        "            cifar10_root=cifar10_root,\n",
        "            cifar10c_root=cifar10c_root,\n",
        "            model_name=model_name,\n",
        "            device=device,\n",
        "            corruption_names_for_training=corruption_pool,\n",
        "            training_severity_strategy=cfg[\"training_severity_strategy\"],\n",
        "            corrupted_fraction=cfg[\"corrupted_fraction\"],\n",
        "            freeze_fraction=cfg[\"freeze_fraction\"],\n",
        "            lr=cfg[\"lr\"],\n",
        "            epochs=cfg[\"epochs\"],\n",
        "            batch_size=128,\n",
        "            num_workers=4,\n",
        "            evaluate_severities=[1,2,3,4,5],\n",
        "            results_root=results_root\n",
        "        )\n",
        "        # compute simple aggregate metrics for the run\n",
        "        metrics = res[\"metrics\"]\n",
        "        values = list(metrics.values())\n",
        "        mean_all = float(np.mean(values)) if values else 0.0\n",
        "        mean_sev3 = float(np.mean([v for (k,v) in metrics.items() if k[1]==3])) if values else 0.0\n",
        "        summary_rows.append({\n",
        "            \"tag\": tag,\n",
        "            \"mean_top1_all\": mean_all,\n",
        "            \"mean_top1_sev3\": mean_sev3,\n",
        "            \"ckpt\": res[\"meta\"][\"metrics_csv\"],\n",
        "            \"meta\": res[\"meta\"]\n",
        "        })\n",
        "    except Exception as ex:\n",
        "        print(f\"ERROR in config {tag}: {ex}\")\n",
        "        summary_rows.append({\"tag\": tag, \"error\": str(ex)})\n",
        "\n",
        "# Save summary table\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_csv = Path(results_root) / \"summary_table.csv\"\n",
        "summary_df.to_csv(summary_csv, index=False)\n",
        "print(\"\\nAblation grid finished. Summary saved to:\", summary_csv)\n",
        "print(summary_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbyA38_xBgeA",
        "outputId": "2df81230-0d30-48b8-a641-afce8498ceee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running config: cf0.25_ff0.7_lr1e-4_e3\n",
            " -> wrote results/ablation/metrics_cf0.25_ff0.7_lr1e-4_e3.csv, metadata results/ablation/metadata_cf0.25_ff0.7_lr1e-4_e3.json, checkpoint results/ablation/finetuned_model_cf0.25_ff0.7_lr1e-4_e3.pth\n",
            "Running config: cf0.5_ff0.7_lr1e-4_e3\n",
            " -> wrote results/ablation/metrics_cf0.5_ff0.7_lr1e-4_e3.csv, metadata results/ablation/metadata_cf0.5_ff0.7_lr1e-4_e3.json, checkpoint results/ablation/finetuned_model_cf0.5_ff0.7_lr1e-4_e3.pth\n",
            "Running config: cf0.75_ff0.7_lr1e-4_e3\n",
            " -> wrote results/ablation/metrics_cf0.75_ff0.7_lr1e-4_e3.csv, metadata results/ablation/metadata_cf0.75_ff0.7_lr1e-4_e3.json, checkpoint results/ablation/finetuned_model_cf0.75_ff0.7_lr1e-4_e3.pth\n",
            "Running config: cf0.5_ff0.5_lr1e-4_e3\n",
            " -> wrote results/ablation/metrics_cf0.5_ff0.5_lr1e-4_e3.csv, metadata results/ablation/metadata_cf0.5_ff0.5_lr1e-4_e3.json, checkpoint results/ablation/finetuned_model_cf0.5_ff0.5_lr1e-4_e3.pth\n",
            "Running config: cf0.5_ff0.9_lr1e-4_e3\n",
            " -> wrote results/ablation/metrics_cf0.5_ff0.9_lr1e-4_e3.csv, metadata results/ablation/metadata_cf0.5_ff0.9_lr1e-4_e3.json, checkpoint results/ablation/finetuned_model_cf0.5_ff0.9_lr1e-4_e3.pth\n",
            "\n",
            "Ablation grid runs complete. Summary saved to: results/ablation/summary_table.csv\n",
            "                      tag  mean_top1_all  mean_top1_sev3\n",
            "0  cf0.25_ff0.7_lr1e-4_e3        58.6038         59.3637\n",
            "1   cf0.5_ff0.7_lr1e-4_e3        58.7252         59.5689\n",
            "2  cf0.75_ff0.7_lr1e-4_e3        58.8346         59.7478\n",
            "3   cf0.5_ff0.5_lr1e-4_e3        58.8512         59.7900\n",
            "4   cf0.5_ff0.9_lr1e-4_e3        58.5325         59.2210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Aggregate results, show top runs, produce comparison plot vs baseline\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "results_root = Path(\"results/ablation\")\n",
        "summary_csv = results_root / \"summary_table.csv\"\n",
        "baseline_csv = Path(\"results/baseline_metrics.csv\")  # Week2 baseline\n",
        "\n",
        "# Load summary\n",
        "if summary_csv.exists():\n",
        "    summary_df = pd.read_csv(summary_csv)\n",
        "else:\n",
        "    print(\"No summary_table.csv found at\", summary_csv)\n",
        "    summary_df = pd.DataFrame()\n",
        "\n",
        "# Print ranked by mean_top1_all (higher is better)\n",
        "if not summary_df.empty and \"mean_top1_all\" in summary_df.columns:\n",
        "    ranked = summary_df.sort_values(by=\"mean_top1_all\", ascending=False)\n",
        "    print(\"Top runs by mean_top1_all:\")\n",
        "    display(ranked.head(10))\n",
        "else:\n",
        "    print(\"Summary table empty or missing metrics.\")\n",
        "\n",
        "# If baseline exists, compute delta for best run and create plot comparing average per corruption\n",
        "def load_metrics_csv(path: Path) -> Dict[Tuple[str,int], float]:\n",
        "    out = {}\n",
        "    if not path.exists():\n",
        "        return out\n",
        "    import csv\n",
        "    with open(path, newline=\"\") as f:\n",
        "        r = csv.DictReader(f)\n",
        "        for row in r:\n",
        "            out[(row[\"corruption\"], int(row[\"severity\"]))] = float(row[\"top1_accuracy\"])\n",
        "    return out\n",
        "\n",
        "if not summary_df.empty and baseline_csv.exists():\n",
        "    # choose best run\n",
        "    best_row = summary_df.sort_values(by=\"mean_top1_all\", ascending=False).iloc[0]\n",
        "    best_tag = best_row[\"tag\"]\n",
        "    best_metrics_path = results_root / f\"metrics_{best_tag}.csv\"\n",
        "    baseline_metrics = load_metrics_csv(baseline_csv)\n",
        "    best_metrics = load_metrics_csv(best_metrics_path)\n",
        "\n",
        "    # compute per-corruption average across severities present\n",
        "    corruptions = sorted({k[0] for k in best_metrics.keys()})\n",
        "    avg_baseline = []\n",
        "    avg_best = []\n",
        "    labels = []\n",
        "    for c in corruptions:\n",
        "        b_vals = [v for (k,v) in baseline_metrics.items() if k[0] == c]\n",
        "        f_vals = [v for (k,v) in best_metrics.items() if k[0] == c]\n",
        "        if not b_vals or not f_vals:\n",
        "            continue\n",
        "        avg_baseline.append(np.mean(b_vals))\n",
        "        avg_best.append(np.mean(f_vals))\n",
        "        labels.append(c)\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35\n",
        "    plt.figure(figsize=(max(8, len(labels)*0.45), 5))\n",
        "    plt.bar(x - width/2, avg_baseline, width, label=\"baseline\")\n",
        "    plt.bar(x + width/2, avg_best, width, label=f\"best_{best_tag}\")\n",
        "    plt.xticks(x, labels, rotation=45, ha=\"right\")\n",
        "    plt.ylabel(\"Top-1 Accuracy (%)\")\n",
        "    plt.title(\"Baseline vs Best Ablation Run (avg across severities)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plot_out = results_root / \"plots\" / f\"baseline_vs_best_{best_tag}.png\"\n",
        "    plot_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig(plot_out, dpi=200)\n",
        "    print(\"Saved comparison plot to\", plot_out)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping comparison plot (summary or baseline missing).\")\n",
        "\n",
        "print(\"Aggregation complete. Check results/ablation for per-run CSVs, metadata, checkpoints, and plots.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "fCPJivkZBBUV",
        "outputId": "cbaf16dc-4603-4975-90c9-fe5e9c49df9f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top runs by mean_top1_all:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      tag  mean_top1_all  mean_top1_sev3  \\\n",
              "3   cf0.5_ff0.5_lr1e-4_e3        58.8512         59.7900   \n",
              "2  cf0.75_ff0.7_lr1e-4_e3        58.8346         59.7478   \n",
              "1   cf0.5_ff0.7_lr1e-4_e3        58.7252         59.5689   \n",
              "0  cf0.25_ff0.7_lr1e-4_e3        58.6038         59.3637   \n",
              "4   cf0.5_ff0.9_lr1e-4_e3        58.5325         59.2210   \n",
              "\n",
              "                                         metrics_csv  \\\n",
              "3  results/ablation/metrics_cf0.5_ff0.5_lr1e-4_e3...   \n",
              "2  results/ablation/metrics_cf0.75_ff0.7_lr1e-4_e...   \n",
              "1  results/ablation/metrics_cf0.5_ff0.7_lr1e-4_e3...   \n",
              "0  results/ablation/metrics_cf0.25_ff0.7_lr1e-4_e...   \n",
              "4  results/ablation/metrics_cf0.5_ff0.9_lr1e-4_e3...   \n",
              "\n",
              "                                                ckpt  \\\n",
              "3  results/ablation/finetuned_model_cf0.5_ff0.5_l...   \n",
              "2  results/ablation/finetuned_model_cf0.75_ff0.7_...   \n",
              "1  results/ablation/finetuned_model_cf0.5_ff0.7_l...   \n",
              "0  results/ablation/finetuned_model_cf0.25_ff0.7_...   \n",
              "4  results/ablation/finetuned_model_cf0.5_ff0.9_l...   \n",
              "\n",
              "                                                meta  \n",
              "3  {'tag': 'cf0.5_ff0.5_lr1e-4_e3', 'corrupted_fr...  \n",
              "2  {'tag': 'cf0.75_ff0.7_lr1e-4_e3', 'corrupted_f...  \n",
              "1  {'tag': 'cf0.5_ff0.7_lr1e-4_e3', 'corrupted_fr...  \n",
              "0  {'tag': 'cf0.25_ff0.7_lr1e-4_e3', 'corrupted_f...  \n",
              "4  {'tag': 'cf0.5_ff0.9_lr1e-4_e3', 'corrupted_fr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bba62e0d-1515-4f3e-bf38-dcd4e36fa345\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>mean_top1_all</th>\n",
              "      <th>mean_top1_sev3</th>\n",
              "      <th>metrics_csv</th>\n",
              "      <th>ckpt</th>\n",
              "      <th>meta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cf0.5_ff0.5_lr1e-4_e3</td>\n",
              "      <td>58.8512</td>\n",
              "      <td>59.7900</td>\n",
              "      <td>results/ablation/metrics_cf0.5_ff0.5_lr1e-4_e3...</td>\n",
              "      <td>results/ablation/finetuned_model_cf0.5_ff0.5_l...</td>\n",
              "      <td>{'tag': 'cf0.5_ff0.5_lr1e-4_e3', 'corrupted_fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cf0.75_ff0.7_lr1e-4_e3</td>\n",
              "      <td>58.8346</td>\n",
              "      <td>59.7478</td>\n",
              "      <td>results/ablation/metrics_cf0.75_ff0.7_lr1e-4_e...</td>\n",
              "      <td>results/ablation/finetuned_model_cf0.75_ff0.7_...</td>\n",
              "      <td>{'tag': 'cf0.75_ff0.7_lr1e-4_e3', 'corrupted_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cf0.5_ff0.7_lr1e-4_e3</td>\n",
              "      <td>58.7252</td>\n",
              "      <td>59.5689</td>\n",
              "      <td>results/ablation/metrics_cf0.5_ff0.7_lr1e-4_e3...</td>\n",
              "      <td>results/ablation/finetuned_model_cf0.5_ff0.7_l...</td>\n",
              "      <td>{'tag': 'cf0.5_ff0.7_lr1e-4_e3', 'corrupted_fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cf0.25_ff0.7_lr1e-4_e3</td>\n",
              "      <td>58.6038</td>\n",
              "      <td>59.3637</td>\n",
              "      <td>results/ablation/metrics_cf0.25_ff0.7_lr1e-4_e...</td>\n",
              "      <td>results/ablation/finetuned_model_cf0.25_ff0.7_...</td>\n",
              "      <td>{'tag': 'cf0.25_ff0.7_lr1e-4_e3', 'corrupted_f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cf0.5_ff0.9_lr1e-4_e3</td>\n",
              "      <td>58.5325</td>\n",
              "      <td>59.2210</td>\n",
              "      <td>results/ablation/metrics_cf0.5_ff0.9_lr1e-4_e3...</td>\n",
              "      <td>results/ablation/finetuned_model_cf0.5_ff0.9_l...</td>\n",
              "      <td>{'tag': 'cf0.5_ff0.9_lr1e-4_e3', 'corrupted_fr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bba62e0d-1515-4f3e-bf38-dcd4e36fa345')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bba62e0d-1515-4f3e-bf38-dcd4e36fa345 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bba62e0d-1515-4f3e-bf38-dcd4e36fa345');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a6e8856c-8467-4809-ad6a-4bb6fa23c9bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6e8856c-8467-4809-ad6a-4bb6fa23c9bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a6e8856c-8467-4809-ad6a-4bb6fa23c9bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nAggregation complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"cf0.75_ff0.7_lr1e-4_e3\",\n          \"cf0.5_ff0.9_lr1e-4_e3\",\n          \"cf0.5_ff0.7_lr1e-4_e3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_top1_all\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1400686188980249,\n        \"min\": 58.5325,\n        \"max\": 58.8512,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          58.8346,\n          58.5325,\n          58.7252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_top1_sev3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24461395503936423,\n        \"min\": 59.221,\n        \"max\": 59.79,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          59.7478,\n          59.221,\n          59.5689\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metrics_csv\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"results/ablation/metrics_cf0.75_ff0.7_lr1e-4_e3.csv\",\n          \"results/ablation/metrics_cf0.5_ff0.9_lr1e-4_e3.csv\",\n          \"results/ablation/metrics_cf0.5_ff0.7_lr1e-4_e3.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ckpt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"results/ablation/finetuned_model_cf0.75_ff0.7_lr1e-4_e3.pth\",\n          \"results/ablation/finetuned_model_cf0.5_ff0.9_lr1e-4_e3.pth\",\n          \"results/ablation/finetuned_model_cf0.5_ff0.7_lr1e-4_e3.pth\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"meta\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"{'tag': 'cf0.75_ff0.7_lr1e-4_e3', 'corrupted_fraction': 0.75, 'freeze_fraction': 0.7, 'lr': 0.0001, 'epochs': 3, 'training_severity_strategy': 'single-3', 'metrics_csv': 'results/ablation/metrics_cf0.75_ff0.7_lr1e-4_e3.csv', 'created_seconds': 0}\",\n          \"{'tag': 'cf0.5_ff0.9_lr1e-4_e3', 'corrupted_fraction': 0.5, 'freeze_fraction': 0.9, 'lr': 0.0001, 'epochs': 3, 'training_severity_strategy': 'single-3', 'metrics_csv': 'results/ablation/metrics_cf0.5_ff0.9_lr1e-4_e3.csv', 'created_seconds': 0}\",\n          \"{'tag': 'cf0.5_ff0.7_lr1e-4_e3', 'corrupted_fraction': 0.5, 'freeze_fraction': 0.7, 'lr': 0.0001, 'epochs': 3, 'training_severity_strategy': 'single-3', 'metrics_csv': 'results/ablation/metrics_cf0.5_ff0.7_lr1e-4_e3.csv', 'created_seconds': 0}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved comparison plot to results/ablation/plots/baseline_vs_best_cf0.5_ff0.5_lr1e-4_e3.png\n",
            "\n",
            "Top 10 improvements (corruption,severity) -> delta%:\n",
            "motion_blur, sev=3 -> 4.70%\n",
            "impulse_noise, sev=3 -> 4.38%\n",
            "defocus_blur, sev=3 -> 4.23%\n",
            "zoom_blur, sev=3 -> 4.09%\n",
            "gaussian_noise, sev=3 -> 4.02%\n",
            "defocus_blur, sev=2 -> 2.87%\n",
            "gaussian_noise, sev=4 -> 2.83%\n",
            "motion_blur, sev=4 -> 2.64%\n",
            "gaussian_noise, sev=2 -> 2.57%\n",
            "motion_blur, sev=2 -> 2.56%\n",
            "\n",
            "Aggregation complete. Check results/ablation for per-run CSVs, metadata, checkpoints, and plots.\n"
          ]
        }
      ]
    }
  ]
}
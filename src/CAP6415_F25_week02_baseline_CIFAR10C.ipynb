{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "6R832YeZBV3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import datetime\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def log_event(message: str) -> None:\n",
        "    \"\"\"Prints a timestamped log message.\"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] {message}\")\n",
        "\n",
        "\n",
        "def run_command(command: str) -> Tuple[int, str]:\n",
        "    \"\"\"Runs a shell command, returning (exit_code, output).\"\"\"\n",
        "    process = subprocess.Popen(\n",
        "        command,\n",
        "        shell=True,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "    output, _ = process.communicate()\n",
        "    return process.returncode, output\n",
        "\n",
        "\n",
        "def ensure_kaggle_config() -> bool:\n",
        "    \"\"\"Ensures kaggle.json exists and configures the Kaggle directory.\"\"\"\n",
        "    if not os.path.isfile(\"kaggle.json\"):\n",
        "        log_event(\"ERROR: kaggle.json not found. Please upload it.\")\n",
        "        return False\n",
        "\n",
        "    run_command(\"mkdir -p ~/.kaggle\")\n",
        "    run_command(\"cp kaggle.json ~/.kaggle/\")\n",
        "    run_command(\"chmod 600 ~/.kaggle/kaggle.json\")\n",
        "\n",
        "    log_event(\"Kaggle API credentials configured successfully.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def install_kaggle_api() -> None:\n",
        "    \"\"\"Ensures Kaggle API is installed.\"\"\"\n",
        "    log_event(\"Installing Kaggle API if missing...\")\n",
        "    run_command(\"pip install -q kaggle\")\n",
        "    log_event(\"Kaggle API installation attempted.\")\n",
        "\n",
        "\n",
        "def download_dataset(dataset_path: str) -> bool:\n",
        "    \"\"\"Attempts to download a Kaggle dataset.\"\"\"\n",
        "    log_event(f\"Starting dataset download: {dataset_path}\")\n",
        "    command = f\"kaggle datasets download -d {dataset_path}\"\n",
        "    code, output = run_command(command)\n",
        "\n",
        "    if code != 0:\n",
        "        log_event(\"ERROR: Kaggle download failed.\")\n",
        "        log_event(f\"Command Output:\\n{output}\")\n",
        "        return False\n",
        "\n",
        "    log_event(\"Dataset downloaded successfully.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def unzip_dataset(dataset_path: str) -> bool:\n",
        "    \"\"\"Attempts to unzip the downloaded dataset zip file.\"\"\"\n",
        "    zip_filename = f\"{dataset_path.split('/')[-1]}.zip\"\n",
        "\n",
        "    if not os.path.exists(zip_filename):\n",
        "        log_event(f\"ERROR: Expected zip file '{zip_filename}' not found.\")\n",
        "        return False\n",
        "\n",
        "    log_event(f\"Unzipping '{zip_filename}'...\")\n",
        "    code, output = run_command(f\"unzip -q {zip_filename}\")\n",
        "\n",
        "    if code != 0:\n",
        "        log_event(\"ERROR: Unzip failed.\")\n",
        "        log_event(f\"Command Output:\\n{output}\")\n",
        "        return False\n",
        "\n",
        "    log_event(\"Unzip completed successfully.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def download_kaggle_dataset(dataset_path: str) -> None:\n",
        "    \"\"\"Orchestrates full dataset download and extraction.\"\"\"\n",
        "    install_kaggle_api()\n",
        "\n",
        "    if not ensure_kaggle_config():\n",
        "        return\n",
        "\n",
        "    if not download_dataset(dataset_path):\n",
        "        log_event(\"Download process terminated due to errors.\")\n",
        "        return\n",
        "\n",
        "    if not unzip_dataset(dataset_path):\n",
        "        log_event(\"Unzip process terminated due to errors.\")\n",
        "        return\n",
        "\n",
        "    log_event(\"Dataset download and extraction completed successfully.\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "download_kaggle_dataset(\"harshadakhatu/cifar-10-c\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlisuoma5gVz",
        "outputId": "0e1544c7-10c9-4c05-8450-fe455faff38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-11-17 03:49:13] Installing Kaggle API if missing...\n",
            "[2025-11-17 03:49:18] Kaggle API installation attempted.\n",
            "[2025-11-17 03:49:18] Kaggle API credentials configured successfully.\n",
            "[2025-11-17 03:49:18] Starting dataset download: harshadakhatu/cifar-10-c\n",
            "[2025-11-17 03:51:54] Dataset downloaded successfully.\n",
            "[2025-11-17 03:51:54] Unzipping 'cifar-10-c.zip'...\n",
            "[2025-11-17 03:52:36] Unzip completed successfully.\n",
            "[2025-11-17 03:52:36] Dataset download and extraction completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory path\n",
        "directory_path = \"/content/CIFAR-10-C\"\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
        "    # List all files and directories within the specified path\n",
        "    files_and_dirs = os.listdir(directory_path)\n",
        "    print(f\"Contents of '{directory_path}':\")\n",
        "    for item in files_and_dirs:\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"The directory '{directory_path}' does not exist or is not a directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6VTQ-ig8d6x",
        "outputId": "b16e5176-39f1-4b23-e245-d25eb81c1d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of '/content/CIFAR-10-C':\n",
            "speckle_noise.npy\n",
            "gaussian_blur.npy\n",
            "fog.npy\n",
            "impulse_noise.npy\n",
            "jpeg_compression.npy\n",
            "motion_blur.npy\n",
            "snow.npy\n",
            "zoom_blur.npy\n",
            "saturate.npy\n",
            "spatter.npy\n",
            "labels.npy\n",
            "defocus_blur.npy\n",
            "shot_noise.npy\n",
            "gaussian_noise.npy\n",
            "brightness.npy\n",
            "glass_blur.npy\n",
            "elastic_transform.npy\n",
            "frost.npy\n",
            "pixelate.npy\n",
            "contrast.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `inspect_cifar10c.py`:  inspect /content/CIFAR-10-C .npy files\n"
      ],
      "metadata": {
        "id": "HWNWNWho_RAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect /content/CIFAR-10-C .npy files\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "ROOT = Path(\"/content/CIFAR-10-C\")   # change only if your path differs\n",
        "OUT = Path(\"results\")\n",
        "SAMPLES = OUT / \"samples\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "SAMPLES.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_image_array(arr: np.ndarray):\n",
        "    \"\"\"Heuristic check whether array looks like images (H/W/C shape and small H/W dimensions).\"\"\"\n",
        "    if arr.ndim == 4:\n",
        "        n, h, w, c = arr.shape\n",
        "        if c in (1,3) and (h <= 1024 and w <= 1024):\n",
        "            return True\n",
        "    if arr.ndim == 4 and arr.shape[1] in (1,3) and arr.shape[2] <= 1024:\n",
        "        # maybe N, C, H, W\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def to_uint8_image(arr: np.ndarray):\n",
        "    \"\"\"Convert array slice to uint8 HxW(xC) for saving. Accepts floats in [0,1] or ints [0,255].\"\"\"\n",
        "    if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
        "        img = np.clip(arr, 0.0, 1.0)\n",
        "        img = (img * 255.0).round().astype(np.uint8)\n",
        "    else:\n",
        "        img = arr.astype(np.uint8)\n",
        "    # if CHW -> HWC\n",
        "    if img.ndim == 3 and img.shape[0] in (1,3):\n",
        "        img = np.transpose(img, (1,2,0))\n",
        "    # if grayscale single channel -> HxW\n",
        "    if img.ndim == 3 and img.shape[2] == 1:\n",
        "        img = img[:,:,0]\n",
        "    return img\n",
        "\n",
        "report = {}\n",
        "files = sorted([p for p in ROOT.iterdir() if p.suffix == \".npy\"])\n",
        "if not files:\n",
        "    raise SystemExit(f\"No .npy files found in {ROOT}. Check path and rerun.\")\n",
        "\n",
        "print(f\"Found {len(files)} .npy files in {ROOT}\\n\")\n",
        "for p in files:\n",
        "    name = p.name\n",
        "    print(f\"Loading {name} ...\", end=\" \", flush=True)\n",
        "    arr = np.load(p)\n",
        "    print(\"done.\")\n",
        "    info = {\n",
        "        \"path\": str(p),\n",
        "        \"shape\": list(arr.shape),\n",
        "        \"dtype\": str(arr.dtype),\n",
        "        \"nbytes\": int(arr.nbytes) if hasattr(arr, \"nbytes\") else None,\n",
        "    }\n",
        "\n",
        "    # basic statistics if numeric\n",
        "    try:\n",
        "        info[\"min\"] = float(np.min(arr)) if arr.size>0 else None\n",
        "        info[\"max\"] = float(np.max(arr)) if arr.size>0 else None\n",
        "        info[\"mean\"] = float(np.mean(arr)) if arr.size>0 else None\n",
        "        info[\"std\"] = float(np.std(arr)) if arr.size>0 else None\n",
        "    except Exception as e:\n",
        "        info[\"stats_error\"] = str(e)\n",
        "\n",
        "    # Labels detection: likely 1D vector with length 10000\n",
        "    if arr.ndim == 1:\n",
        "        unique, counts = np.unique(arr, return_counts=True)\n",
        "        info[\"is_label_array\"] = True\n",
        "        info[\"unique_count\"] = int(len(unique))\n",
        "        info[\"length\"] = int(arr.shape[0])\n",
        "        info[\"unique_sample\"] = unique[:10].tolist()\n",
        "        info[\"counts_sample\"] = counts[:10].tolist()\n",
        "        # Save sample of labels to JSON-friendly list (first 200)\n",
        "        info[\"first_labels_sample\"] = arr[:200].tolist()\n",
        "    else:\n",
        "        info[\"is_label_array\"] = False\n",
        "\n",
        "    # Image file heuristics and per-severity analysis\n",
        "    if is_image_array(arr):\n",
        "        info[\"looks_like_images\"] = True\n",
        "        # Normalize shape to (N, H, W, C)\n",
        "        if arr.ndim == 4:\n",
        "            if arr.shape[1] in (1,3) and arr.shape[2] <= 1024:\n",
        "                # shape (N, C, H, W) -> convert to (N, H, W, C)\n",
        "                if arr.shape[1] in (1,3) and arr.shape[3] <= 4:\n",
        "                    # unexpected ordering, but handle common CHW or HWC\n",
        "                    pass\n",
        "            # Try to detect ordering\n",
        "            n = arr.shape[0]\n",
        "            if arr.shape[-1] in (1,3) and arr.shape[1] not in (1,3):\n",
        "                # likely (N,H,W,C)\n",
        "                n, h, w, c = arr.shape\n",
        "                arr_hwc = arr\n",
        "            elif arr.shape[1] in (1,3):\n",
        "                # likely (N,C,H,W) -> convert\n",
        "                n, c, h, w = arr.shape\n",
        "                arr_hwc = np.transpose(arr, (0,2,3,1))\n",
        "            else:\n",
        "                # fallback: treat as (N,H,W,C)\n",
        "                n, h, w, c = arr.shape\n",
        "                arr_hwc = arr\n",
        "        else:\n",
        "            info[\"image_format_note\"] = \"unexpected ndim for images\"\n",
        "            arr_hwc = arr\n",
        "\n",
        "        info[\"num_images_total\"] = int(arr_hwc.shape[0])\n",
        "\n",
        "        # detect severity grouping: divisible by 10000 (common CIFAR-10-C)\n",
        "        if arr_hwc.shape[0] % 10000 == 0:\n",
        "            groups = arr_hwc.shape[0] // 10000\n",
        "            info[\"num_severities_in_file\"] = int(groups)\n",
        "            info[\"per_severity_counts\"] = [10000] * groups\n",
        "            # compute simple per-severity stats (mean pixel value per channel)\n",
        "            per_sev = []\n",
        "            for s in range(groups):\n",
        "                start = s * 10000\n",
        "                end = (s + 1) * 10000\n",
        "                subset = arr_hwc[start:end].astype(np.float32) / (255.0 if arr_hwc.dtype != np.float32 and arr_hwc.dtype != np.float64 else 1.0)\n",
        "                # per-channel mean (HWC -> axis=(0,1,2), channel last)\n",
        "                mean_channels = list(np.mean(subset, axis=(0,1,2)).tolist())\n",
        "                std_channels = list(np.std(subset, axis=(0,1,2)).tolist())\n",
        "                per_sev.append({\"mean_channels\": mean_channels, \"std_channels\": std_channels})\n",
        "                # save one representative image per severity (first image)\n",
        "                try:\n",
        "                    img = to_uint8_image(subset[0])\n",
        "                    fname = SAMPLES / f\"{p.stem}_s{s+1}.png\"\n",
        "                    Image.fromarray(img).save(fname)\n",
        "                    per_sev[-1][\"saved_sample\"] = str(fname)\n",
        "                except Exception as e:\n",
        "                    per_sev[-1][\"saved_sample_error\"] = str(e)\n",
        "            info[\"per_severity_stats\"] = per_sev\n",
        "        else:\n",
        "            # not divisible by 10000: report number and attempt to treat as single-severity set\n",
        "            info[\"num_severities_in_file\"] = None\n",
        "            info[\"per_severity_counts\"] = [int(arr_hwc.shape[0])]\n",
        "            try:\n",
        "                subset = arr_hwc.astype(np.float32) / (255.0 if arr_hwc.dtype != np.float32 and arr_hwc.dtype != np.float64 else 1.0)\n",
        "                mean_channels = list(np.mean(subset, axis=(0,1,2)).tolist())\n",
        "                std_channels = list(np.std(subset, axis=(0,1,2)).tolist())\n",
        "                info[\"per_severity_stats\"] = [{\"mean_channels\": mean_channels, \"std_channels\": std_channels}]\n",
        "                # save sample\n",
        "                img = to_uint8_image(subset[0])\n",
        "                fname = SAMPLES / f\"{p.stem}_s1.png\"\n",
        "                Image.fromarray(img).save(fname)\n",
        "                info[\"per_severity_stats\"][0][\"saved_sample\"] = str(fname)\n",
        "            except Exception as e:\n",
        "                info[\"per_severity_stats\"] = [{\"error\": str(e)}]\n",
        "    else:\n",
        "        info[\"looks_like_images\"] = False\n",
        "\n",
        "    report[name] = info\n",
        "\n",
        "# Write JSON report\n",
        "report_path = OUT / \"inspect_report.json\"\n",
        "with open(report_path, \"w\") as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print(\"\\nInspection complete.\")\n",
        "print(f\"Report written to: {report_path}\")\n",
        "print(f\"Sample images (one per severity) saved under: {SAMPLES}\")\n",
        "print(\"\\nQuick summary (file : num_images / num_severities):\")\n",
        "for fname, info in report.items():\n",
        "    if info.get(\"looks_like_images\"):\n",
        "        print(f\"- {fname}: {info.get('num_images_total')} images, severities={info.get('num_severities_in_file')}\")\n",
        "    elif info.get(\"is_label_array\"):\n",
        "        print(f\"- {fname}: labels length={info.get('length')}, unique={info.get('unique_count')}\")\n",
        "    else:\n",
        "        print(f\"- {fname}: shape={info.get('shape')} (non-image)\")\n",
        "\n",
        "# Print path to report for easy copy-paste\n",
        "print(str(report_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45wHWK9s9NEQ",
        "outputId": "6665e674-ef38-4687-a456-fbd83c1f47ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 .npy files in /content/CIFAR-10-C\n",
            "\n",
            "Loading brightness.npy ... done.\n",
            "Loading contrast.npy ... done.\n",
            "Loading defocus_blur.npy ... done.\n",
            "Loading elastic_transform.npy ... done.\n",
            "Loading fog.npy ... done.\n",
            "Loading frost.npy ... done.\n",
            "Loading gaussian_blur.npy ... done.\n",
            "Loading gaussian_noise.npy ... done.\n",
            "Loading glass_blur.npy ... done.\n",
            "Loading impulse_noise.npy ... done.\n",
            "Loading jpeg_compression.npy ... done.\n",
            "Loading labels.npy ... done.\n",
            "Loading motion_blur.npy ... done.\n",
            "Loading pixelate.npy ... done.\n",
            "Loading saturate.npy ... done.\n",
            "Loading shot_noise.npy ... done.\n",
            "Loading snow.npy ... done.\n",
            "Loading spatter.npy ... done.\n",
            "Loading speckle_noise.npy ... done.\n",
            "Loading zoom_blur.npy ... done.\n",
            "\n",
            "Inspection complete.\n",
            "Report written to: results/inspect_report.json\n",
            "Sample images (one per severity) saved under: results/samples\n",
            "\n",
            "Quick summary (file : num_images / num_severities):\n",
            "- brightness.npy: 50000 images, severities=5\n",
            "- contrast.npy: 50000 images, severities=5\n",
            "- defocus_blur.npy: 50000 images, severities=5\n",
            "- elastic_transform.npy: 50000 images, severities=5\n",
            "- fog.npy: 50000 images, severities=5\n",
            "- frost.npy: 50000 images, severities=5\n",
            "- gaussian_blur.npy: 50000 images, severities=5\n",
            "- gaussian_noise.npy: 50000 images, severities=5\n",
            "- glass_blur.npy: 50000 images, severities=5\n",
            "- impulse_noise.npy: 50000 images, severities=5\n",
            "- jpeg_compression.npy: 50000 images, severities=5\n",
            "- labels.npy: labels length=50000, unique=10\n",
            "- motion_blur.npy: 50000 images, severities=5\n",
            "- pixelate.npy: 50000 images, severities=5\n",
            "- saturate.npy: 50000 images, severities=5\n",
            "- shot_noise.npy: 50000 images, severities=5\n",
            "- snow.npy: 50000 images, severities=5\n",
            "- spatter.npy: 50000 images, severities=5\n",
            "- speckle_noise.npy: 50000 images, severities=5\n",
            "- zoom_blur.npy: 50000 images, severities=5\n",
            "\n",
            "If you want me to update loader/eval code, paste the contents of:\n",
            "results/inspect_report.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `dataloader.py` : CIFAR-10-C dataloader"
      ],
      "metadata": {
        "id": "heVcqkhuAv5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10-C dataloader & helpers (run this cell first)\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# CIFAR normalization constants\n",
        "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR_STD = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "def list_corruptions(cifar10c_root: str) -> List[str]:\n",
        "    \"\"\"Return sorted list of corruption names (without .npy) in the folder.\"\"\"\n",
        "    root = Path(cifar10c_root)\n",
        "    if not root.exists():\n",
        "        raise FileNotFoundError(f\"{cifar10c_root} not found\")\n",
        "    return sorted([p.stem for p in root.glob(\"*.npy\") if p.name.lower() != \"labels.npy\"])\n",
        "\n",
        "def _to_chw_tensor(np_images: np.ndarray) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Convert numpy images to CHW torch tensor float32 in [0,1].\n",
        "    Accepts (N,H,W,C) or (N,C,H,W).\n",
        "    \"\"\"\n",
        "    if np_images.ndim != 4:\n",
        "        raise ValueError(f\"Expected 4D image array, got shape {np_images.shape}\")\n",
        "    # If last dim is channel (H,W,C)\n",
        "    if np_images.shape[-1] in (1, 3) and np_images.shape[1] not in (1, 3):\n",
        "        np_images = np.transpose(np_images, (0, 3, 1, 2))  # -> (N,C,H,W)\n",
        "    elif np_images.shape[1] in (1, 3):\n",
        "        # already (N,C,H,W)\n",
        "        pass\n",
        "    else:\n",
        "        # fallback: assume (N,H,W,C)\n",
        "        np_images = np.transpose(np_images, (0, 3, 1, 2))\n",
        "    if np.issubdtype(np_images.dtype, np.integer):\n",
        "        images = np_images.astype(\"float32\") / 255.0\n",
        "    else:\n",
        "        images = np_images.astype(\"float32\")\n",
        "    return torch.from_numpy(images)  # (N,C,H,W)\n",
        "\n",
        "def _normalize(images: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Normalize CHW tensor using CIFAR mean/std (applied per-channel).\"\"\"\n",
        "    mean = torch.tensor(CIFAR_MEAN, dtype=images.dtype).view(1, 3, 1, 1)\n",
        "    std = torch.tensor(CIFAR_STD, dtype=images.dtype).view(1, 3, 1, 1)\n",
        "    return (images - mean) / std\n",
        "\n",
        "def load_cifar10c_corruption(\n",
        "    cifar10c_root: str,\n",
        "    corruption_name: str,\n",
        "    severity_level: int = 1,\n",
        "    batch_size: int = 128,\n",
        "    num_workers: int = 4,\n",
        "    pin_memory: bool = False\n",
        ") -> DataLoader:\n",
        "    \"\"\"\n",
        "    Load one corruption+severity as a DataLoader.\n",
        "\n",
        "    - Handles corruption files with shape (50000,32,32,3) (5 severities concatenated)\n",
        "      or (10000,32,32,3) (single severity).\n",
        "    - Handles labels.npy with length 50000 (per-corrupted-image) or 10000 (per-original-test).\n",
        "    \"\"\"\n",
        "    root = Path(cifar10c_root)\n",
        "    data_path = root / f\"{corruption_name}.npy\"\n",
        "    labels_path = root / \"labels.npy\"\n",
        "\n",
        "    if not data_path.exists():\n",
        "        raise FileNotFoundError(f\"{data_path} not found\")\n",
        "    if not labels_path.exists():\n",
        "        raise FileNotFoundError(f\"{labels_path} not found\")\n",
        "\n",
        "    arr = np.load(str(data_path))\n",
        "    labels = np.load(str(labels_path))\n",
        "\n",
        "    n_images = arr.shape[0]\n",
        "    # detect number of groups/severities (common: 50000 -> groups=5 each 10000)\n",
        "    groups = n_images // 10000 if (n_images % 10000 == 0) else 1\n",
        "    if not (1 <= severity_level <= groups):\n",
        "        raise ValueError(f\"severity_level must be 1..{groups} for file {data_path.name}\")\n",
        "\n",
        "    if groups == 1:\n",
        "        images_slice = arr\n",
        "    else:\n",
        "        per_group = n_images // groups\n",
        "        s0 = (severity_level - 1) * per_group\n",
        "        s1 = severity_level * per_group\n",
        "        images_slice = arr[s0:s1]\n",
        "\n",
        "    # Determine labels for the images_slice\n",
        "    L = labels.shape[0]\n",
        "    if L == images_slice.shape[0]:\n",
        "        labels_slice = labels\n",
        "    elif L == n_images:\n",
        "        if groups == 1:\n",
        "            labels_slice = labels\n",
        "        else:\n",
        "            s0 = (severity_level - 1) * (n_images // groups)\n",
        "            s1 = severity_level * (n_images // groups)\n",
        "            labels_slice = labels[s0:s1]\n",
        "    elif L == 10000 and images_slice.shape[0] == 10000:\n",
        "        labels_slice = labels\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Incompatible labels length ({L}) and images ({images_slice.shape[0]}) \"\n",
        "            f\"for file {data_path.name}. Inspect files with the inspector.\"\n",
        "        )\n",
        "\n",
        "    images_tensor = _to_chw_tensor(images_slice)  # (N,C,H,W)\n",
        "    images_tensor = _normalize(images_tensor)\n",
        "    labels_tensor = torch.from_numpy(labels_slice.astype(\"int64\"))\n",
        "\n",
        "    dataset = TensorDataset(images_tensor, labels_tensor)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=num_workers, pin_memory=pin_memory)\n",
        "    return loader\n",
        "\n",
        "def load_all_corruptions(\n",
        "    cifar10c_root: str,\n",
        "    severity_level: int = 1,\n",
        "    batch_size: int = 128,\n",
        "    num_workers: int = 4\n",
        ") -> Dict[str, DataLoader]:\n",
        "    \"\"\"Return dict: corruption_name -> DataLoader for that severity.\"\"\"\n",
        "    names = list_corruptions(cifar10c_root)\n",
        "    return {n: load_cifar10c_corruption(cifar10c_root, n, severity_level, batch_size, num_workers) for n in names}\n",
        "\n",
        "print(\"CIFAR-10-C loader functions defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_frRlSsZA1BW",
        "outputId": "018a0950-31d5-4464-bf15-48af09768b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10-C loader functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `evaluate_baseline.py` : Evaluate pretrained small models (EfficientNet-B0, MobileNetV3-Small) on CIFAR-10-C.\n"
      ],
      "metadata": {
        "id": "Xx4g1E98A7JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline model(s) on CIFAR-10-C using the dataloader above\n",
        "\n",
        "# --- CONFIGURE ---\n",
        "cifar10c_root = \"/content/CIFAR-10-C\"   # path we used\n",
        "model_name = \"efficientnet_b0\"           # \"efficientnet_b0\" or \"mobilenet_v3_small\"\n",
        "severities = [1]                         # list e.g. [1] or [1,2,3,4,5]\n",
        "batch_size = 256\n",
        "num_workers = 4\n",
        "device_str = \"cuda\"                      # or \"cpu\"\n",
        "output_csv = \"results/baseline_metrics.csv\"\n",
        "checkpoint_path: Optional[str] = None    # set to \"/content/finetuned_model.pth\" if we have one\n",
        "\n",
        "# --- END CONFIG ---\n",
        "\n",
        "# Silence warnings\n",
        "import warnings, os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "# Optional: reduce PIL / image warnings (if present)\n",
        "try:\n",
        "    from PIL import Image\n",
        "    Image.MAX_IMAGE_PIXELS = None\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import csv\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "# Ensure results directory exists\n",
        "Path(output_csv).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def load_model(name: str, num_classes: int = 10, device: Optional[torch.device] = None) -> torch.nn.Module:\n",
        "    \"\"\"Load and adapt models from torchvision (simple, robust approach).\"\"\"\n",
        "    name = name.lower()\n",
        "    if name == \"efficientnet_b0\":\n",
        "        # note: torchvision may emit UserWarning about pretrained weights; we've silenced warnings above\n",
        "        model = models.efficientnet_b0(pretrained=True)\n",
        "        if hasattr(model, \"classifier\") and isinstance(model.classifier, torch.nn.Sequential):\n",
        "            in_features = model.classifier[1].in_features\n",
        "            model.classifier[1] = torch.nn.Linear(in_features, num_classes)\n",
        "        else:\n",
        "            for m in model.modules():\n",
        "                if isinstance(m, torch.nn.Linear):\n",
        "                    pass\n",
        "    elif name == \"mobilenet_v3_small\":\n",
        "        model = models.mobilenet_v3_small(pretrained=True)\n",
        "        last_linear_name = None\n",
        "        for nm, m in model.named_modules():\n",
        "            if isinstance(m, torch.nn.Linear):\n",
        "                last_linear_name = nm\n",
        "        if last_linear_name is None:\n",
        "            raise RuntimeError(\"Could not find Linear layer to adapt MobileNetV3 head.\")\n",
        "        parts = last_linear_name.split('.')\n",
        "        parent = model\n",
        "        for p in parts[:-1]:\n",
        "            parent = getattr(parent, p)\n",
        "        old = getattr(parent, parts[-1])\n",
        "        setattr(parent, parts[-1], torch.nn.Linear(old.in_features, num_classes))\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {name}\")\n",
        "    if device is not None:\n",
        "        model.to(device)\n",
        "    return model\n",
        "\n",
        "def evaluate_loader(model: torch.nn.Module, loader: torch.utils.data.DataLoader, device: torch.device) -> float:\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100.0 * correct / total if total > 0 else 0.0\n",
        "\n",
        "# load model\n",
        "model = load_model(model_name, num_classes=10, device=device)\n",
        "if checkpoint_path:\n",
        "    if Path(checkpoint_path).exists():\n",
        "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "        print(f\"Loaded checkpoint: {checkpoint_path}\")\n",
        "    else:\n",
        "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
        "\n",
        "# list corruptions\n",
        "from IPython.display import display\n",
        "from math import ceil\n",
        "corruptions = list_corruptions(cifar10c_root)\n",
        "print(f\"Found {len(corruptions)} corruption files: {corruptions}\")\n",
        "\n",
        "# evaluate & write CSV\n",
        "with open(output_csv, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"corruption\", \"severity\", \"top1_accuracy\"])\n",
        "    for corruption in corruptions:\n",
        "        for sev in severities:\n",
        "            print(f\"Evaluating {corruption} severity={sev} ...\", flush=True)\n",
        "            loader = load_cifar10c_corruption(\n",
        "                cifar10c_root=cifar10c_root,\n",
        "                corruption_name=corruption,\n",
        "                severity_level=sev,\n",
        "                batch_size=batch_size,\n",
        "                num_workers=num_workers,\n",
        "                pin_memory=(device.type == \"cuda\")\n",
        "            )\n",
        "            acc = evaluate_loader(model, loader, device)\n",
        "            print(f\" -> {acc:.2f}%\")\n",
        "            writer.writerow([corruption, sev, f\"{acc:.4f}\"])\n",
        "print(f\"Saved baseline metrics to: {output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhDIiVFfB-CP",
        "outputId": "240155f2-001c-4675-8c5b-4755bcc2921b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote results/baseline_metrics.csv (96 rows incl. header). Showing first 20 data rows:\n",
            "corruption,severity,top1_accuracy\n",
            "clean,0,86.7000\n",
            "brightness,1,81.3952\n",
            "brightness,2,74.1505\n",
            "brightness,3,67.8790\n",
            "brightness,4,60.8751\n",
            "brightness,5,54.9182\n",
            "contrast,1,81.9474\n",
            "contrast,2,76.6098\n",
            "contrast,3,69.2146\n",
            "contrast,4,63.5699\n",
            "contrast,5,56.3001\n",
            "defocus_blur,1,75.3061\n",
            "defocus_blur,2,63.1296\n",
            "defocus_blur,3,49.0157\n",
            "defocus_blur,4,35.5549\n",
            "defocus_blur,5,22.4257\n",
            "elastic_transform,1,80.2629\n",
            "elastic_transform,2,72.3196\n",
            "elastic_transform,3,65.0963\n",
            "elastic_transform,4,57.4527\n"
          ]
        }
      ]
    }
  ]
}